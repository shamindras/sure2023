<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Supervised Learning</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Supervised Learning
]
.subtitle[
## K-Nearest Neighbors Regression and Classification
]
.date[
### June 30th, 2023
]

---






## Supervised learning so far...

Linear Regression: Assumptions

--

- The relationship is __linear__

`$$Y_{i}=\beta_{0}+\beta_{1} X_{i}+\epsilon_{i}, \quad \text { for } i=1,2, \dots, n$$`

$$ \epsilon_i \overset{iid}{\sim}N(0, \sigma^2) \quad \text{ with constant variance } \sigma^2 $$

- Error terms must be __independently, identically distributed__ from Normal distribution (actually three assumptions!)

  - Normality
  
  - Independence
  
  - Homoscedasticity

  
Each of these assumptions must be __checked__

--

Assumptions (in general) make estimation and inference easier but may not always be appropriate

---

## Parametric models

When we make assumptions about distributions, we are saying that we can summarize them with a set of __parameters__

Examples...

--

- Normal distribution: `\(N(\mu, \sigma^2)\)`, the __mean__ `\(\mu\)` and __variance__ `\(\sigma^2\)` are parameters

--

- Poisson distribution: `\(\text{Pois}(\lambda)\)`, the only parameter is `\(\lambda\)`, which is both the __mean and variance__

--

- Simple linear regression: `\(Y=\beta_{0}+\beta_{1} X\)`, the coefficients (__intercept__ `\(\beta_0\)` and __slope__ `\(\beta_1\)`) are parameters

--

But what if we don't want to make assumptions __a priori__ about our data?


---

## Nonparametric models

Still assume a function mapping the predictors to the response

$$ Y = f(X) $$
And we still want to __estimate__ this regression or classification function

But now we do not assume that this function takes any __particular form__ (e.g. do not assume that the relationship is linear)

--

.pull-left[

### Benefits

- Very flexible, allowing for fitting to very complex relationships

- Often show better performance, more accurate predictions

]

.pull-right[

### Limitations

- Frequently less interpretable

- Prone to overfitting

- Computational concerns (require more data, take longer to train)

]

---

## Regression vs. classification

- __Regression__ models: estimate _average_ value of response

- __Classification__ models: determine _the most likely_ class of a set of discrete response variable classes

Linear (simple or multiple) models `\(\rightarrow\)` regression

Logistic models `\(\rightarrow\)` classification!

--

Examples of classification:

- Binary: given covariates like running yards and completion percentage, can we predict __whether or not__ a QB is likely to be a Hall-of-Famer?

- Multi-class: from predictors like tumor size, location, and cell types, can we determine __which kind__ of cancer a patient has?

--

Question of interest determines which type of model to use

Many nonparametric methods (e.g. KNN) can be used either for classification __OR__ regression, just change the final outcome

---

## Setup: Binary classification problem

.pull-left[

`\(Y = f(X_1, X_2)\)`

`\(Y \in \{0, 1\}\)`

How might we model `\(f(X_1, X_2)\)`?

__"Decision boundary"__

Example settings:

- QB's running and passing yards `\((X_1, X_2)\)`, HOF status `\((Y)\)`

- Patient's length of inpatient rehab stay and report of outpatient stress `\((X_1, X_2)\)`, substance abuse relapse `\((Y)\)`

]


.pull_right[

&lt;img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRLpgBIfLPTFlVsF32It6Ues8tZNDzAYFlMOA&amp;usqp=CAU" width="50%" style="display: block; margin: auto;" /&gt;

]

---

## K-Nearest Neighbors Classification

.pull-left[

Classify a __new point__ based on a majority vote of the __k__ points closest to it in space

__Close?__ Use Euclidean distance

`$$d(x_i, x_j) = \sqrt{(x_{i1}-x_{j1})^2 + \cdots + (x_{ip}-x_{jp})^2}$$`

Have to choose how many neighbors to query: which value of __k__ to pick

]


.pull_right[

&lt;img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRLpgBIfLPTFlVsF32It6Ues8tZNDzAYFlMOA&amp;usqp=CAU" width="50%" style="display: block; margin: auto;" /&gt;

]

---

### Different values of k lead to different decision boundaries

&lt;img src="https://elvyna.github.io/images/posts/2019-01-28-knn-explained/6-k-affects-decision-boundary.png?style=centerme" width="100%" style="display: block; margin: auto;" /&gt;

--

Excellent illustration of the __bias-variance tradeoff__

--

As __k increases__, the __variance decreases__ (different training samples will produce more similar decision boundaries), but the __bias increases__ (the decision boundary gets further from the truth)

---

## Picking the number of neighbors

The number of neighbors __k__ is a __hyperparameter__

Tune this value using a train-test split or using cross-validation

__Note__: 1NN classification will have zero training error... __why__ ?

--

&lt;img src="https://kevinzakka.github.io/assets/knn/teaser.png" width="30%" style="display: block; margin: auto;" /&gt;

--

#### Ideally: balance the flexibility, allowing for a complex decision boundary, __but__ don't fit to the noise

---

## Data: NFL field goal attempts

Created dataset using [`nflscrapR-data`](https://github.com/ryurko/nflscrapR-data) of all NFL field goal attempts from 2009 to 2019


```r
nfl_fg_attempts &lt;- read_csv("https://shorturl.at/mCGN2") %&gt;% 
  filter(pbp_season == 2014) %&gt;% 
  mutate(is_fg_made = as_factor(is_fg_made))
head(nfl_fg_attempts)
```

```
## # A tibble: 6 × 11
##   kicker_player_id kicker_player_name   qtr score_differential home_team posteam
##   &lt;chr&gt;            &lt;chr&gt;              &lt;dbl&gt;              &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  
## 1 00-0025944       S.Hauschka             1                  0 SEA       SEA    
## 2 00-0025580       M.Crosby               2                 -3 SEA       GB     
## 3 00-0025944       S.Hauschka             3                  7 SEA       SEA    
## 4 00-0019536       S.Graham               1                  0 ATL       NO     
## 5 00-0019536       S.Graham               1                  3 ATL       NO     
## 6 00-0020578       M.Bryant               2                -13 ATL       ATL    
## # ℹ 5 more variables: posteam_type &lt;chr&gt;, kick_distance &lt;dbl&gt;,
## #   pbp_season &lt;dbl&gt;, abs_score_diff &lt;dbl&gt;, is_fg_made &lt;fct&gt;
```

__Response__: is the field goal made?

---

## Predicting field goals

.pull-left[

Explanatory variables: 

Kick distance and score differential



```r
ggplot(nfl_fg_attempts) +
  geom_point(aes(x = kick_distance, 
                 y = score_differential,
                 color = is_fg_made), 
             size = 0.7) +
  theme_bw()
```

Does there appear to be a relationship between these predictors and the success of field goal attempts?

]

.pull-right[
&lt;img src="19-slides_files/figure-html/unnamed-chunk-6-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

## KNN classification

Using the [FNN package](https://rdrr.io/cran/FNN/) (fast implementation of KNN models)

Separate predictors from the response column:


```r
fg_x &lt;- dplyr::select(nfl_fg_attempts, kick_distance, score_differential)
fg_y &lt;- nfl_fg_attempts$is_fg_made
```

Give `knn()` 

- a training set with all explanatory columns `train`

- a "test" set including all explanatory columns `test`

  - if you provide the same set for both, it will give predictions on the training set

- a vector of true classifications for the training set `cl`

- a value for number of nearest neighbors `k`

- instructions for which `algorithm` to use ("brute" means that it will do a brute-force search, but it can also do tree-based searches)

---

## Fitting a KNN classifier

Trying `\(k=1\)`:


```r
library(FNN)

init_knn &lt;- knn(train = fg_x, test = fg_x, cl = fg_y, k = 1, algorithm = "brute")
```

This outputs a vector of predicted classes for the "test" set (in this case, predictions on the training set)

--

How well does this model perform?

```r
mean(nfl_fg_attempts$is_fg_made == init_knn)
```

```
## [1] 0.9177665
```

__92%__ But we said that 1NN would achieve zero training error?

--

In this dataset, there are multiple observations for some distance-differential combinations, which might have both made and missed field goals, so it then takes the majority vote among those "equivalent" points (see the documentation!)

---

## Training vs. test

But, as we know, we should not assess models based on training error, we need some measure of holdout performance:

Split the data, train the model, then assess performance on the test set

(Yet another way to manually code a train-test split)

```r
set.seed(50)
train_ids &lt;- sample(1:nrow(nfl_fg_attempts), 
                    ceiling(0.75 * nrow(nfl_fg_attempts)))

train_nfl &lt;- nfl_fg_attempts[train_ids, ]
test_nfl &lt;- nfl_fg_attempts[-train_ids, ]

# separate predictors and response, again
train_x &lt;- dplyr::select(train_nfl, kick_distance, score_differential)
train_y &lt;- train_nfl$is_fg_made
test_x &lt;- dplyr::select(test_nfl, kick_distance, score_differential)
test_y &lt;- test_nfl$is_fg_made
```

---

## Assessing 1NN

1 Nearest Neighbor classifier: How well does it perform on the training data?

```r
one_nn_train_preds &lt;- knn(train = train_x, test = train_x, cl = train_y, k = 1, algorithm = "brute")
mean(train_y == one_nn_train_preds)
```

```
## [1] 0.9418133
```
--

... But what about on the test data?


```r
one_nn_test_preds &lt;- knn(train = train_x, test = test_x, cl = train_y, k = 1, algorithm = "brute")
mean(test_y == one_nn_test_preds)
```

```
## [1] 0.7479675
```
Performance decreases! We're overfitting!

---

## Which value of k to pick?

As a demonstration, let's loop through possible values of k and see which ends up having the best holdout performance


```r
errs_train &lt;- rep(0, 12)
errs_test &lt;- rep(0, 12)
k_vals &lt;- 1:12

for(k in k_vals) {
  
  train_preds &lt;- knn(train = train_x, test = train_x, cl = train_y, k = k, algorithm = "brute")
  errs_train[k] &lt;- mean(!train_y == train_preds)
  
  test_preds &lt;- knn(train = train_x, test = test_x, cl = train_y, k = k, algorithm = "brute")
  errs_test[k] &lt;- mean(!test_y == test_preds)
}
```

--

Side note: beyond k = 12, the model predicts success for the entire test set

---

## Plot training and test error

.pull-left[


```r
errors &lt;- bind_cols(train_err = errs_train,
                    test_err = errs_test,
                    k = k_vals)

errors %&gt;% 
  pivot_longer(c(train_err, test_err), 
               names_to = "err_type") %&gt;% 
  ggplot(aes(x = k, y = value, 
             color = err_type)) +
  geom_point() +
  geom_line() +
  labs(y = "Misclassification Rate", 
       color = "Type of error") +
  theme_bw()
```


]

.pull-right[
&lt;img src="19-slides_files/figure-html/unnamed-chunk-14-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

## But wait, there's more!

The k-nearest-neighbors algorithm can also be used for __regression__!

As before:

- Find the k points closest to your new observation (based on Euclidean distance)

--

But now,

- Rather than taking a _majority vote_ to determine a class, take the __average response__ among the neighbors

- Predict this average value as the response for the new point: 


`$$\hat{f}(x^*) = \text{Ave}(y_i | x_i \in N_k(x^*))$$`

--

(__Side Note__: You can also do cool stuff like weighting those responses based on how close they are to the new point! Lots of modifications to knn regression out there)

---

## Brief KNN Regression Example

.pull-left[

Gapminder data again


```r
library(dslabs)
clean_gapminder &lt;- as_tibble(gapminder) %&gt;%
  filter(year == 2011, !is.na(gdp)) %&gt;%
  mutate(log_gdp = log(gdp))

gdp_plot &lt;- clean_gapminder %&gt;%
  ggplot(aes(x = log_gdp,
             y = life_expectancy)) +
  geom_point(alpha = 0.5) +
* geom_smooth(method = "lm") +
  theme_bw() +
  labs(x = "log(GDP)",
       y = "Life expectancy")
gdp_plot
```

]

.pull-right[
&lt;img src="19-slides_files/figure-html/unnamed-chunk-15-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

---

## KNN Regression for Life Expectancy

.pull-left[

```r
k2_le &lt;- knn.reg(
  train = clean_gapminder$log_gdp,
  y = clean_gapminder$life_expectancy,
  k = 2)
k5_le &lt;- knn.reg(
  train = clean_gapminder$log_gdp,
  y = clean_gapminder$life_expectancy,
  k = 5)
k15_le &lt;- knn.reg(
  train = clean_gapminder$log_gdp,
  y = clean_gapminder$life_expectancy,
  k = 15)

gdp_plot +
* geom_line(aes(x = log_gdp, y = k2_le$pred),
            color = "darkgreen") +
* geom_line(aes(x = log_gdp, y = k5_le$pred),
            color = "darkred") +
* geom_line(aes(x = log_gdp, y = k15_le$pred),
            color = "purple")
```


]

.pull-right[
&lt;img src="19-slides_files/figure-html/unnamed-chunk-16-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

---

## KNN with tidymodels

Of course, we can also use the tidymodels framework to fit and use a KNN regression model:


```r
library(tidymodels)
knn_reg_mod &lt;- nearest_neighbor(
  mode = "regression",
  engine = "kknn",
  neighbors = 5,         # we could also tune this with cross-validation
  weight_func = NULL,    # for weighted KNN!
  dist_power = NULL      # for use with a different distance metric
)

gapminder_knn_fit &lt;- knn_reg_mod %&gt;% 
  fit(
    life_expectancy ~ log_gdp,
    data = clean_gapminder
  )
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
