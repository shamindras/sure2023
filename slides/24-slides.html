<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Advanced Topics in Classification</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Advanced Topics in Classification
]
.subtitle[
## Multinomial logistic regression (++)
]
.date[
### July 14th, 2023
]

---






## Example: NFL Expected Points

What does football __play-by-play__ data look like? Each row is a play with contextual information:

- __Possession team:__ team with the ball, on offense (opposing team is on defense)

- __Down:__ 4 downs to advance the ball 10 (or more) yards

  - New set of downs, else turnover to defense
  
- __Yards to go:__ distance in yards to advance 

- __Yard line:__ distance in yards away from opponent's endzone (100 to 0) - the field position

- __Time remaining:__ seconds remaining in game, each game is 3600 seconds long

  - 4 quarters, halftime in between, followed by a potential overtime (900 seconds)


---

## Example: NFL Expected Points

__Drive:__ a series of plays, changes with possession and the types of scoring events:

- __No Score:__ 0 points - turnover the ball or half/game ends

- __Field Goal:__ 3 points - kick through opponent's goal post

- __Touchdown:__ 7 points - enter opponent's end zone

- __Safety:__ 2 points for opponent - tackled in own endzone

--

__Next Score:__ type of next score (current drive or future drives) with respect to possession team

- For: Touchdown (7), Field Goal (3), Safety (2)

- Against: -Touchdown (-7), -Field Goal (-3), -Safety (-2)

- No Score

_Note: treating point-after-touchdown attempts (PATs) separately_


---

## Example: NFL Expected Points

__Expected Points:__ Measure the value of play in terms of `\(\mathbb{E}[\text{points of next scoring play}]\)`

- i.e., historically, how many points have teams scored when in similar situations?
  
--

__Response__: `\(Y \in\)` {Touchdown (7), Field Goal (3), Safety (2), No Score (0), -Safety (-2), -Field Goal (-3), -Touchdown (-7)} 

__Explanatory variables__: `\(\mathbf{X} =\)` {down, yards to go, yard line, ...} 

--

Want to __estimate the probabilities__ of each scoring event to compute expected points:

- Outcome probabilities: `\(P(Y = y |  \mathbf{X})\)`

- Expected Points `\(= E(Y| \mathbf{X}) = \sum_{y \in Y} y \cdot P(Y=y|\mathbf{X})\)`

--

_How do we model more than two categories???_

---

## Review: logistic regression

Response variable `\(Y\)` has two possible values: 1 or 0, we estimate the probability

$$
p(x) = P(Y = 1 | X = x)
$$

Assuming that we are dealing with two classes, the possible observed values for `\(Y\)` are 0 and 1, 
$$
Y \vert x \sim {\rm Binomial}(n=1,p=\mathbb{E}[Y\vert x]) = \text{Bernoulli}(p = \mathbb{E}[Y\vert x])
$$

--

To limit the regression betweewn `\([0, 1]\)`: use the __logit__ function, aka the __log-odds ratio__

$$
\text{logit}(p(x)) = \log \left[ \frac{p(x)}{1 - p(x)} \right] = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p
$$

--

meaning

`$$p(x) = \frac{e^{\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p}}{1 + e^{\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p}}$$`



---

## [Multinomial logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression)

We can extend this to `\(K\)` classes (via the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)):


`$$P(Y=k^* \mid X=x)=\frac{e^{\beta_{0 k^*}+\beta_{1 k^*} x_{1}+\cdots+\beta_{p k^*} x_{p}}}{\sum_{k=1}^{K} e^{\beta_{0 k}+\beta_{1 k} x_{1}+\cdots+\beta_{p k} x_{p}}}$$`


--

We only estimate coefficients for `\(K - 1\)` classes __relative to reference class__

For example, let `\(K\)` be the reference then we use `\(K - 1\)` logit transformations
  
  - Use `\(\boldsymbol{\beta}\)` for vector of coefficients and `\(\mathbf{X}\)` for matrix of predictors
  
`$$\begin{array}{c}
\log \Big( \frac{P(Y =1 \mid \mathbf{X})}{P(Y=K \mid \mathbf{X})} \Big) = \boldsymbol{\beta}_{1} \cdot \mathbf{X}  \\
\log \Big( \frac{P(Y=2 \mid \mathbf{X})}{P(Y=K \mid \mathbf{X})} \Big) =\boldsymbol{\beta}_{2} \cdot \mathbf{X} \\
\log \Big( \frac{P(Y=K-1 \mid \mathbf{X})}{P(Y=K \mid \mathbf{X})} \Big) =\boldsymbol{\beta}_{K-1} \cdot \mathbf{X}
\end{array}$$`

---

## [Multinomial logistic regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression) for next score

`\(Y \in\)` {Touchdown (7), Field Goal (3), Safety (2), No Score (0), -Safety (-2), -Field Goal (-3), -Touchdown (-7)}

`\(\mathbf{X} =\)` {down, yards to go, yard line, ...} 

--

Model is specified with __six logit transformations__ relative to __No Score__:

`$$\begin{array}{c}
\log \left(\frac{P(Y=\text { Touchdown } \mid \mathbf{X})}{P(Y=\text { No Score } \mid \mathbf{X})}\right)=\mathbf{X} \cdot \boldsymbol{\beta}_{\text {Touchdown }} \\
\log \left(\frac{P(Y=\text { Field Goal } \mid \mathbf{X})}{P(Y=\text { No Score } \mid \mathbf{X})}\right)=\mathbf{X} \cdot \boldsymbol{\beta}_{\text {Field Goal }}, \\
\vdots &amp; \\ \log \left(\frac{P(Y=-\text { Touchdown } \mid \mathbf{X})}{P(Y=\text { No Score } \mid \mathbf{X})}\right)=\mathbf{X} \cdot \boldsymbol{\beta}_{-\text {Touchdown }},
\end{array}$$`


--

- Model is generating probabilities, agnostic of value associated with each next score type

--

- Fit multinomial logistic regression model in `R` with `nnet` package

---

### NFL play-by-play data (2010 to 2020)

Initialized NFL play-by-play dataset with next score in half for each play

- Followed steps in [script by Ben Baldwin](https://github.com/nflverse/nflfastR-data/blob/master/models/model_data.R) (which copies Prof. Yurko's steps [here](https://github.com/ryurko/nflscrapR-models/blob/master/R/init_models/init_ep_fg_models.R))


```r
library(tidyverse)
nfl_ep_model_data &lt;- readRDS(url("https://shorturl.at/BTVZ1"))

nfl_ep_model_data &lt;- nfl_ep_model_data %&gt;%
  mutate(Next_Score_Half = fct_relevel(Next_Score_Half, "No_Score"),
         # log transform of yards to go and indicator for two minute warning:
         log_ydstogo = log(ydstogo),
         # Changing down into a factor variable: 
         down = factor(down))
```


--

How to fit the model? 


```r
init_ep_model &lt;- multinom(Next_Score_Half ~ half_seconds_remaining + yardline_100 + down +
                            log_ydstogo + log_ydstogo*down + yardline_100*down, 
                          data = nfl_ep_model_data, maxit = 300)
```


_What does the `summary()` function return?_

---

### Leave-one-season-out cross-validation


```r
library(nnet)
init_loso_cv_preds &lt;- 
  map_dfr(unique(nfl_ep_model_data$season), 
          function(x) {
            # Separate test and training data:
            test_data &lt;- nfl_ep_model_data %&gt;% filter(season == x)
            train_data &lt;- nfl_ep_model_data %&gt;% filter(season != x)
            
            # Fit multinomial logistic regression model:
            ep_model &lt;- 
              multinom(Next_Score_Half ~ half_seconds_remaining + yardline_100 + down + 
                         log_ydstogo + log_ydstogo*down + yardline_100*down, 
                       data = train_data, maxit = 300)
            
            # Return dataset of class probabilities:
*           predict(ep_model, newdata = test_data, type = "probs") %&gt;%
              as_tibble() %&gt;%
              mutate(Next_Score_Half = test_data$Next_Score_Half,
                     season = x)
              })
```




---

### Calibration results for each scoring event
  

```r
ep_cv_loso_calibration_results &lt;- init_loso_cv_preds %&gt;%
  pivot_longer(No_Score:Touchdown,
               names_to = "next_score_type",
               values_to = "pred_prob") %&gt;%
  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) %&gt;%
  group_by(next_score_type, bin_pred_prob) %&gt;%
  summarize(n_plays = n(), 
            n_scoring_event = length(which(Next_Score_Half == next_score_type)),
            bin_actual_prob = n_scoring_event / n_plays,
*           bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_plays)) %&gt;%
  ungroup() %&gt;%
* mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),
*        bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0))
```

---

### Calibration results for each scoring event


```r
ep_cv_loso_calibration_results %&gt;%
  mutate(next_score_type = fct_relevel(next_score_type, "Opp_Safety", "Opp_Field_Goal", 
                                       "Opp_Touchdown", "No_Score", "Safety", "Field_Goal",
                                       "Touchdown"),
  next_score_type = fct_recode(next_score_type, "-Field Goal (-3)" = "Opp_Field_Goal", 
                               "-Safety (-2)" = "Opp_Safety", "-Touchdown (-7)" = "Opp_Touchdown",
                               "Field Goal (3)" = "Field_Goal", "No Score (0)" = "No_Score",
                               "Touchdown (7)" = "Touchdown", "Safety (2)" = "Safety")) %&gt;%
  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = "dashed") +
  geom_smooth(se = FALSE) + 
  geom_point(aes(size = n_plays)) +
  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + #coord_equal() +   
  scale_x_continuous(limits = c(0,1)) + 
  scale_y_continuous(limits = c(0,1)) + 
  labs(size = "Number of plays", x = "Estimated next score probability", 
       y = "Observed next score probability") + 
  theme_bw() + 
  theme(strip.background = element_blank(), 
        axis.text.x = element_text(angle = 90), 
        legend.position = c(1, .05), legend.justification = c(1, 0)) +
  facet_wrap(~ next_score_type, ncol = 4)
```


---

### Calibration results for each scoring event

&lt;img src="24-slides_files/figure-html/unnamed-chunk-3-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

## Multinomial classification with XGBoost

Use same NFL play-by-play dataset as before but get ready for XGBoost...


```r
nfl_ep_model_data &lt;- nfl_ep_model_data %&gt;%
  mutate(Next_Score_Half = fct_relevel(Next_Score_Half, 
                                       "No_Score", "Safety", "Field_Goal", "Touchdown",
                                       "Opp_Safety", "Opp_Field_Goal", "Opp_Touchdown"),
         next_score_label = as.numeric(Next_Score_Half) - 1) 
model_variables &lt;- c("half_seconds_remaining", "yardline_100", "down", "ydstogo")
```

XGBoost requires the multinomial categories to be numeric starting at 0

---

### Leave-one-season-out cross-validation


```r
xgb_loso_cv_preds &lt;- 
  map_dfr(unique(nfl_ep_model_data$season), function(x) {
            
            # Separate test and training data - scale variables:
            test_data &lt;- nfl_ep_model_data %&gt;% filter(season == x)
            test_data_x &lt;- as.matrix(dplyr::select(test_data, model_variables))
            train_data &lt;- nfl_ep_model_data %&gt;% filter(season != x)
            train_data_x &lt;- as.matrix(dplyr::select(train_data, model_variables))
            train_data_y &lt;- train_data$next_score_label
            
            xgb_model &lt;- xgboost(data = train_data_x, label = train_data_y, nrounds = 100,
                                 max_depth = 3, eta = 0.3, gamma = 0, colsample_bytree = 1,
                                 min_child_weight = 1, subsample = 1, nthread = 1, 
                                 objective = 'multi:softprob', num_class = 7,
                                 eval_metric = 'mlogloss', verbose = 0)
            
            xgb_preds &lt;- matrix(predict(xgb_model, test_data_x), ncol = 7, byrow = TRUE) %&gt;%
              as_tibble()
            colnames(xgb_preds) &lt;- c("No_Score", "Safety", "Field_Goal", "Touchdown",
                                     "Opp_Safety", "Opp_Field_Goal", "Opp_Touchdown")
            xgb_preds %&gt;%
              mutate(Next_Score_Half = test_data$Next_Score_Half,season = x)
            })
```




---

### Calibration results for each scoring event
  

```r
ep_cv_loso_calibration_results &lt;- xgb_loso_cv_preds %&gt;%
  pivot_longer(No_Score:Opp_Touchdown,
               names_to = "next_score_type",
               values_to = "pred_prob") %&gt;%
  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) %&gt;%
  group_by(next_score_type, bin_pred_prob) %&gt;%
  summarize(n_plays = n(), 
            n_scoring_event = length(which(Next_Score_Half == next_score_type)),
            bin_actual_prob = n_scoring_event / n_plays,
*           bin_se = sqrt((bin_actual_prob * (1 - bin_actual_prob)) / n_plays)) %&gt;%
  ungroup() %&gt;%
* mutate(bin_upper = pmin(bin_actual_prob + 2 * bin_se, 1),
*        bin_lower = pmax(bin_actual_prob - 2 * bin_se, 0))
```

---

### Calibration results for each scoring event


```r
ep_cv_loso_calibration_results %&gt;%
  mutate(next_score_type = fct_relevel(next_score_type, "Opp_Safety", "Opp_Field_Goal", 
                                       "Opp_Touchdown", "No_Score", "Safety", "Field_Goal",
                                       "Touchdown"),
  next_score_type = fct_recode(next_score_type, "-Field Goal (-3)" = "Opp_Field_Goal", 
                               "-Safety (-2)" = "Opp_Safety", "-Touchdown (-7)" = "Opp_Touchdown",
                               "Field Goal (3)" = "Field_Goal", "No Score (0)" = "No_Score",
                               "Touchdown (7)" = "Touchdown", "Safety (2)" = "Safety")) %&gt;%
  ggplot(aes(x = bin_pred_prob, y = bin_actual_prob)) +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = "dashed") +
  geom_smooth(se = FALSE) + 
  geom_point(aes(size = n_plays)) +
  geom_errorbar(aes(ymin = bin_lower, ymax = bin_upper)) + #coord_equal() +   
  scale_x_continuous(limits = c(0,1)) + 
  scale_y_continuous(limits = c(0,1)) + 
  labs(size = "Number of plays", x = "Estimated next score probability", 
       y = "Observed next score probability") + 
  theme_bw() + 
  theme(strip.background = element_blank(), 
        axis.text.x = element_text(angle = 90), 
        legend.position = c(1, .05), legend.justification = c(1, 0)) +
  facet_wrap(~ next_score_type, ncol = 4)
```


---

### Calibration results for each scoring event

&lt;img src="24-slides_files/figure-html/unnamed-chunk-5-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

## Model Evaluation for Classification

### Back to a binary example: NFL completion probability

Binary outcome model: `\(Y \in \{\text{Incomplete }(0), \text{Complete }(1) \}\)`


```r
library(tidyverse)
nfl_passing_plays &lt;- 
  read_csv("https://shorturl.at/ADMWZ") %&gt;%
  # Only keep rows with passer and receiver information known:
  filter(!is.na(passer_player_id), !is.na(receiver_player_id), 
         !is.na(epa), !is.na(air_yards), !is.na(pass_location)) %&gt;%
  # Combine passer and receiver unique IDs:
  mutate(passer_name_id = paste0(passer_player_name, ":", passer_player_id),
         receiver_name_id = paste0(receiver_player_name, ":", receiver_player_id))
```


--

Create train and test folds based on games:


```r
set.seed(1985)
game_fold_table &lt;- tibble(game_id = unique(nfl_passing_plays$game_id)) %&gt;%
  mutate(game_fold = sample(rep(1:5, length.out = n()), n()))
nfl_passing_plays &lt;- nfl_passing_plays %&gt;% dplyr::left_join(game_fold_table, by = "game_id")
```


---

## Logistic regression review

Generate data of test predictions with particular model:


```r
logit_cv_preds &lt;- 
  map_dfr(unique(nfl_passing_plays$game_fold), 
          function(test_fold) {
            # Separate test and training data:
            test_data &lt;- nfl_passing_plays %&gt;%
              filter(game_fold == test_fold)
            train_data &lt;- nfl_passing_plays %&gt;%
              filter(game_fold != test_fold)
            
            # Train model:
            logit_model &lt;- glm(complete_pass ~ yardline_100 + shotgun + air_yards + 
                                 pass_location + qb_hit, 
                               data = train_data,family = "binomial")
            
            # Return tibble of holdout results:
            tibble(test_pred_probs = predict(logit_model, newdata = test_data,
                                             type = "response"),
                   test_actual = test_data$complete_pass,
                   game_fold = test_fold) 
          })
```


---

## Holdout performance by fold



```r
logit_cv_preds %&gt;%
  mutate(test_pred = ifelse(test_pred_probs &lt; .5, 0, 1)) %&gt;%
  group_by(game_fold) %&gt;%
  summarize(mcr = mean(test_pred != test_actual)) 
```

```
## # A tibble: 5 × 2
##   game_fold   mcr
##       &lt;int&gt; &lt;dbl&gt;
## 1         1 0.284
## 2         2 0.291
## 3         3 0.294
## 4         4 0.281
## 5         5 0.307
```


--

Let's think more carefully about what's going on here...

---

### Evaluating the prediction threshold

We can really write our classification as a function of some cutoff `\(c\)`:

`$$\hat{Y} = \hat{C}(x)=\left\{\begin{array}{ll}
1 &amp; \hat{p}(x)&gt;c \\
0 &amp; \hat{p}(x) \leq c
\end{array}\right.$$`

--

Given the classifications, we can form a confusion matrix:

&lt;img src="https://bradleyboehmke.github.io/HOML/images/confusion-matrix.png" width="80%" style="display: block; margin: auto;" /&gt;


---

&lt;img src="https://bradleyboehmke.github.io/HOML/images/confusion-matrix.png" width="80%" style="display: block; margin: auto;" /&gt;

We want to __maximize__ all of the following (positive means 1, negative means 0):

- __Accuracy__: How often is the classifier correct? `\(\frac{TP + TN}{total}\)`

--

- __Precision__: How often is it right for predicted positives? `\(\frac{TP}{TP + FP}\)`

--

- __Sensitivity__, aka true positive rate (TPR) or power: How often does it detect positives? `\(\frac{TP}{TP + FN}\)`

--

- __Specificity__, aka true negative rate (TNR), or 1 - false positive rate (FPR): How often does it detect negatives? `\(\frac{TN}{TN + FP}\)`

--

__So how do we handle this?__

---

### We want to balance with high power and low false positive rate

&lt;img src="https://media1.tenor.com/images/f6ec84a0969cb05a08d8c0ae16b847af/tenor.gif?itemid=13078930" width="80%" style="display: block; margin: auto;" /&gt;

---

### Receiver Operating Characteristic (ROC) curve

Check all possible values for the cutoff `\(c\)`, plot the power against false positive rate

Want to maximize the __area under the curve (AUC)__

&lt;img src="https://bradleyboehmke.github.io/HOML/02-modeling-process_files/figure-html/modeling-process-roc-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---

### [`plotROC`](https://cran.r-project.org/web/packages/plotROC/vignettes/examples.html) and holdout AUC

.pull-left[

- `d` stands for disease status (the outcome)

- `m` stands for marker (the prediction)


```r
library(plotROC)
logit_cv_preds %&gt;%
  ggplot() + 
* geom_roc(aes(d = test_actual,
*              m = test_pred_probs),
           labelround = 4) + 
  style_roc() + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", 
              color = "gray") +
  labs(color = "Test fold")
with(logit_cv_preds, 
*    MLmetrics::AUC(test_pred_probs, test_actual))
```


]
.pull-right[
&lt;img src="24-slides_files/figure-html/unnamed-chunk-13-1.png" width="504" style="display: block; margin: auto;" /&gt;

```
## [1] 0.6957778
```

]

---

### [`plotROC`](https://cran.r-project.org/web/packages/plotROC/vignettes/examples.html) and holdout AUC by test fold

.pull-left[


```r
logit_cv_preds %&gt;%
  ggplot() + 
  geom_roc(aes(d = test_actual, 
               m = test_pred_probs,
*              color = as.factor(game_fold)),
*          n.cuts = 0) +
  style_roc() + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", 
              color = "gray") +
  ggthemes::scale_color_colorblind() +
  labs(color = "Test fold") + 
  theme(legend.position = "bottom")
logit_cv_preds %&gt;% group_by(game_fold) %&gt;%
  summarize(auc = MLmetrics::AUC(test_pred_probs, 
                                 test_actual))
```

_There is definitely room for improvement..._

]
.pull-right[
&lt;img src="24-slides_files/figure-html/unnamed-chunk-14-1.png" width="504" style="display: block; margin: auto;" /&gt;

```
## # A tibble: 5 × 2
##   game_fold   auc
##       &lt;int&gt; &lt;dbl&gt;
## 1         1 0.707
## 2         2 0.686
## 3         3 0.699
## 4         4 0.700
## 5         5 0.690
```

]

---

## Tree-based approach?

We need to first convert categorical variables into dummy indicators:


```r
model_data &lt;- nfl_passing_plays %&gt;%
  mutate(play_id = 1:n(),
         complete_pass = as.factor(complete_pass)) %&gt;%
  dplyr::select(play_id, complete_pass, yardline_100, shotgun, air_yards, qb_hit,
                game_fold, pass_location) %&gt;%
  mutate(pass_location_val = 1) %&gt;%
  pivot_wider(id_cols = play_id:game_fold,
              names_from = pass_location, values_from = pass_location_val,
              values_fill = 0) %&gt;%
  dplyr::select(-play_id)
```


---

## Random forests using probability forest

For each tree compute class proportion in terminal node, then take average across all trees


```r
library(ranger)
rf_prob_cv_preds &lt;- 
  map_dfr(unique(model_data$game_fold), 
          function(test_fold) {
            
            # Separate test and training data - scale variables:
            test_data &lt;- model_data %&gt;% filter(game_fold == test_fold)
            
            train_data &lt;- model_data %&gt;% filter(game_fold != test_fold)

            rf_prob_model &lt;-
              ranger(complete_pass ~ ., data = dplyr::select(train_data, -game_fold),
                     probability = TRUE)

            # Return tibble of holdout results:
            tibble(test_pred_probs = 
                     as.numeric(predict(rf_prob_model, data = test_data,
*                                       type = "response")$predictions[,2]),
*                  test_actual = as.numeric(test_data$complete_pass) - 1,
                   game_fold = test_fold) 
          })
```



---

### Random forests using probability forest

.pull-left[


```r
rf_prob_cv_preds %&gt;%
  ggplot() + 
  geom_roc(aes(d = test_actual, 
               m = test_pred_probs,
*              color = as.factor(game_fold)),
*          n.cuts = 0) +
  style_roc() + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", 
              color = "gray") +
  ggthemes::scale_color_colorblind() +
  labs(color = "Test fold") + 
  theme(legend.position = "bottom")
rf_prob_cv_preds %&gt;% group_by(game_fold) %&gt;%
  summarize(auc = MLmetrics::AUC(test_pred_probs, 
                                 test_actual))
```

_Looks like just a modest improvement_

]
.pull-right[
&lt;img src="24-slides_files/figure-html/unnamed-chunk-17-1.png" width="504" style="display: block; margin: auto;" /&gt;

```
## # A tibble: 5 × 2
##   game_fold   auc
##       &lt;int&gt; &lt;dbl&gt;
## 1         1 0.717
## 2         2 0.705
## 3         3 0.707
## 4         4 0.708
## 5         5 0.704
```

]

---

## XGBoost!


```r
library(xgboost)
xgb_cv_preds &lt;- 
  map_dfr(unique(model_data$game_fold), 
          function(test_fold) {
            # Separate test and training data - scale variables:
            test_data &lt;- model_data %&gt;% filter(game_fold == test_fold)
            test_data_x &lt;- as.matrix(dplyr::select(test_data, -complete_pass, -game_fold))
            train_data &lt;- model_data %&gt;% filter(game_fold != test_fold)
            train_data_x &lt;- as.matrix(dplyr::select(train_data, -complete_pass, -game_fold))
            train_data_y &lt;- as.numeric(train_data$complete_pass) - 1
            
*           xgb_model &lt;- xgboost(data = train_data_x, label = train_data_y,
                                 nrounds = 100, max_depth = 3, eta = 0.3, 
                                 gamma = 0, colsample_bytree = 1, min_child_weight = 1,
                                 subsample = 1, nthread = 1,
                                 objective = 'binary:logistic', eval_metric = 'auc', 
                                 verbose = 0)

            # Return tibble of holdout results:
            tibble(test_pred_probs = 
                     as.numeric(predict(xgb_model, newdata = test_data_x, type = "response")),
                   test_actual = as.numeric(test_data$complete_pass) - 1,
                   game_fold = test_fold) 
          })
```


---

### XGBoost

.pull-left[


```r
xgb_cv_preds %&gt;%
  ggplot() + 
  geom_roc(aes(d = test_actual, 
               m = test_pred_probs,
*              color = as.factor(game_fold)),
*          n.cuts = 0) +
  style_roc() + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", 
              color = "gray") +
  ggthemes::scale_color_colorblind() +
  labs(color = "Test fold") + 
  theme(legend.position = "bottom")
xgb_cv_preds %&gt;% group_by(game_fold) %&gt;%
  summarize(auc = MLmetrics::AUC(test_pred_probs, 
                                 test_actual))
```

_Should actually tune this more..._

]
.pull-right[
&lt;img src="24-slides_files/figure-html/unnamed-chunk-19-1.png" width="504" style="display: block; margin: auto;" /&gt;

```
## # A tibble: 5 × 2
##   game_fold   auc
##       &lt;int&gt; &lt;dbl&gt;
## 1         1 0.712
## 2         2 0.708
## 3         3 0.711
## 4         4 0.708
## 5         5 0.697
```

]

---

## All together now...

.pull-left[

```r
bind_rows(
  mutate(logit_cv_preds, type = "logit"),
  mutate(rf_prob_cv_preds, type = "RF"),
  mutate(xgb_cv_preds, type = "XGBoost")) %&gt;%
  ggplot() + 
  geom_roc(aes(d = test_actual, 
               m = test_pred_probs,
*              color = type),
*          n.cuts = 0) +
  style_roc() + 
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", 
              color = "gray") +
  ggthemes::scale_color_colorblind() +
  labs(color = "Model") + 
  theme(legend.position = "bottom")
```

]
.pull-right[
&lt;img src="24-slides_files/figure-html/unnamed-chunk-20-1.png" width="504" style="display: block; margin: auto;" /&gt;

Pretty similar performance across all models...

]

---

### Explaining predictions with [SHAP-values](https://christophm.github.io/interpretable-ml-book/shap.html)

SHAP-values are based on [Shapley values](https://christophm.github.io/interpretable-ml-book/shapley.html) (an idea from game theory) and are used to measure the contributions from each feature in the model to the prediction for an individual observation

Shapley value `\(\phi_i^j\)` for feature value `\(j\)` for observation `\(i\)` can be interpreted as:

- the value of feature `\(j\)` contributed `\(\phi_i^j\)` to the prediction of observation `\(i\)` compared to the average prediction for the dataset

- linear regression coefficients function in the same way

--

Can use them in multiple ways:

- View total importance: `\(\frac{1}{n}\sum |\phi_i^j|\)`

- View distribution of `\(\phi_i^j\)` for each feature

- Plot `\(\phi_i^j\)` against feature value for partial dependence


---

### [`SHAPforxgboost`](https://cran.r-project.org/web/packages/SHAPforxgboost/readme/README.html)

Fit model on full data then [extract SHAP-values with `SHAPforxgboost`](https://www.kaggle.com/rikdifos/shap-make-algorithms-interpretable)


```r
train_data_x &lt;- as.matrix(dplyr::select(model_data, -complete_pass, -game_fold))
train_data_y &lt;- as.numeric(model_data$complete_pass) - 1
xgb_model &lt;- xgboost(data = train_data_x, label = train_data_y, nrounds = 100, max_depth = 3, 
                     eta = 0.3, gamma = 0, colsample_bytree = 1, min_child_weight = 1, 
                     subsample = 1, nthread = 1, objective = 'binary:logistic', 
                     eval_metric = 'auc', verbose = 0)
library(SHAPforxgboost)
shap_value_list &lt;- shap.values(xgb_model, X_train = train_data_x)
shap.plot.summary.wrap1(xgb_model, X = train_data_x)
```

&lt;img src="24-slides_files/figure-html/unnamed-chunk-21-1.png" width="504" style="display: block; margin: auto;" /&gt;



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
