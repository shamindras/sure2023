[
  {
    "objectID": "assignment/demo-lab-01.html",
    "href": "assignment/demo-lab-01.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "To install R (latest release: 4.3.0), please go to https://www.r-project.org and choose your system. Click the download R link in the middle of the page under “Getting Started.” Download and install the installer files (executable, pkg, etc) that correspond to your system.\nAlthough you can use R without any integrated development environment (IDE), you will need to install RStudio, by far the most popular IDE for R, for this summer. Basically, it makes your life with R much easier and we will be using it throughout the program. To install RStudio, please go to https://www.rstudio.com/products/rstudio/download/#download and choose your system. The installer is preferred. If you have RStudio installed but not the latest version, just download the latest installer and install."
  },
  {
    "objectID": "assignment/demo-lab-01.html#install-r-and-rstudio",
    "href": "assignment/demo-lab-01.html#install-r-and-rstudio",
    "title": "Getting Started with R",
    "section": "",
    "text": "To install R (latest release: 4.3.0), please go to https://www.r-project.org and choose your system. Click the download R link in the middle of the page under “Getting Started.” Download and install the installer files (executable, pkg, etc) that correspond to your system.\nAlthough you can use R without any integrated development environment (IDE), you will need to install RStudio, by far the most popular IDE for R, for this summer. Basically, it makes your life with R much easier and we will be using it throughout the program. To install RStudio, please go to https://www.rstudio.com/products/rstudio/download/#download and choose your system. The installer is preferred. If you have RStudio installed but not the latest version, just download the latest installer and install."
  },
  {
    "objectID": "assignment/demo-lab-01.html#typical-workflow",
    "href": "assignment/demo-lab-01.html#typical-workflow",
    "title": "Getting Started with R",
    "section": "Typical workflow",
    "text": "Typical workflow\nFollow the TA for a walkthrough of each component in R Studio.\n\nWriting R scripts\nYou can type commands directly into the Console (lower left pane), but this can become quite tedious and annoying when your work becomes more complex. Instead, you will be spending most of your time writing code in R Scripts. An R Script is a file type which R recognizes as storing R commands and is saved as a .R file. R Scripts are useful as we can edit our code before sending it to be run in the console. You can create a new R Script by clicking on the top left symbol in RStudio and selecting R Script.\n\n\nUsing R Markdown\nAn R Markdown(.Rmd) file is a dynamic document combining the R and the markdown. It contains the reproducible R code along with the narration that a reader needs to understand your work. (This file itself is generated by R Markdown.) If you are familiar with the laTeX syntax, math mode works like a charm in almost the same way:\n\\[\nf (x) = \\frac{1}{\\sqrt{2\\pi}} \\exp \\left( - \\frac{x^2}{2} \\right)\n\\]\nThe chunks of embedded R codes are:\n\n#R codes here\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\nRunning a Rmarkdown file and converting it into a reader-friendly documents require the rmarkdown and knitr package. All the lab documents will be Rmarkdown files so you need to know how to knit them. We recommend to knit as html file but if you have LaTex installed, you can knit as PDF.\nFor more detailed information, R Markdown Cheatsheet and the online book are helpful. (For RStudio users, easily accessible from Help -&gt; Cheatsheets)\nAlternatively, you can create a R Notebook file which is similar to R Markdown, but instead allows you to knit code chunks separately without having to re-knit (aka re-run!) the entire file. Notebooks will only render HTML files, but can they be very useful for simultaneously coding, generating results, and making a presentable file to others."
  },
  {
    "objectID": "assignment/demo-lab-01.html#install-r-packages",
    "href": "assignment/demo-lab-01.html#install-r-packages",
    "title": "Getting Started with R",
    "section": "Install R packages",
    "text": "Install R packages\nR performs a wide variety of functions, such as data manipulation, modeling, and visualization. The extensive code base beyond the built-in functions are managed by packages created from numerous statisticians and developers. The Comprehensive R Archive Network (CRAN) manages the open-source distribution and the quality control of the R packages.\nTo install a R package, using the function install.packages and put the package name in the parentheses and the quote. While this is preferred, for those using RStudio, you can also go to “Tools” then “Install Packages” and then input the package name.\n\ninstall.packages(\"tidyverse\")\n\nImportant Note: NEVER install new packages in a code block in an .Rmd file. Always install new packages at the command line / Console. That is, the install.packages() function should NEVER be in your code chunks (unless they are commented out using #). The library() function, however, will be used throughout your code: The library() function loads packages only after they are installed.\nIf in any time you get a message says: “Do you want to install from sources the package which needs compilation?” Choose “No” will tend to bring less troubles. (Note: This happens when the bleeding-edge version package is available, but not yet compiled for each OS distribution. In many case, you can just proceed without the source compilation.)\nEach package only needs to be installed once. Whenever you want to use functions defined in the package, you need to load the package with the statement:\n\nlibrary(tidyverse)\n\nHere is a list of packages that we may need (but not limited to) in the following lectures and/or labs. Please make sure you can install all of them. If you fail to install any package, please update the R and RStudio first and check the error message for any other packages that need to install first.\n\nlibrary(tidyverse)\nlibrary(devtools)\nlibrary(rmarkdown)\nlibrary(knitr)\nlibrary(ranger)\nlibrary(glmnet)"
  },
  {
    "objectID": "assignment/demo-lab-01.html#basic-data-type-and-operators",
    "href": "assignment/demo-lab-01.html#basic-data-type-and-operators",
    "title": "Getting Started with R",
    "section": "Basic data type and operators",
    "text": "Basic data type and operators\n\nData type: Vector\nThe basic unit of R is a vector. A vector v is a collection of values of the same type and the type could be:\n\nnumeric (double/integer number): digits with optional decimal point\n\n\nv1 &lt;- c(1, 5, 8.3, 0.02, 99999)\ntypeof(v1)\n\n[1] \"double\"\n\n\n\ncharacter: a string (or word) in double or single quotes, “…” or ‘…’.\n\n\nv2 &lt;- c(\"apple\", \"banana\", \"3 chairs\", \"dimension1\", \"&gt;-&lt;\")\ntypeof(v2)\n\n[1] \"character\"\n\n\n\nlogical: TRUE and FALSE\n\n\nv3 &lt;- c(TRUE, FALSE, FALSE)\ntypeof(v3)\n\n[1] \"logical\"\n\n\nNote: Oftentimes, factor is used to encode a character vector into unique numeric vector.\n\nplayer_type &lt;- c(\"Batter\", \"Batter\", \"Hitter\", \"Batter\", \"Hitter\")\nplayer_type &lt;- factor(player_type)\nstr(player_type)\n\n Factor w/ 2 levels \"Batter\",\"Hitter\": 1 1 2 1 2\n\ntypeof(player_type)\n\n[1] \"integer\"\n\n\n\n\nData type: Lists\nVector can store only single data type:\n\ntypeof(c(1, TRUE, \"apple\"))\n\n[1] \"character\"\n\n\nList is a vector of vectors which can store different data types of vectors:\n\nroster &lt;- list(\n  name = c(\"Shamindra\", \"Meg\", \"Quang\", \"Nick\", \"YJ\", \"Beomjo\"),\n  role = c(\"Instructor\", \"Instructor\", \"TA\", \"TA\", \"TA\", \"TA\"),\n  is_TA = c(FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)\n)\n\nstr(roster)\n\nList of 3\n $ name : chr [1:6] \"Shamindra\" \"Meg\" \"Quang\" \"Nick\" ...\n $ role : chr [1:6] \"Instructor\" \"Instructor\" \"TA\" \"TA\" ...\n $ is_TA: logi [1:6] FALSE FALSE TRUE TRUE TRUE TRUE\n\n\nR uses a specific type of list, data frame, containing the same number of rows with unique row names.\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\ntypeof(iris)\n\n[1] \"list\"\n\n\n\n\nOperators\nWe can preform element-wise actions on vectors through the operators:\n\nArithmetic: + - * / ^ (and, for integer division, %/% is quotient, %% is remainder)\n\n\nv1 &lt;- c(1,2,3)\nv2 &lt;- c(4,5,6)\n\nv1 + v2\n\n[1] 5 7 9\n\nv1 * v2\n\n[1]  4 10 18\n\nv2 %% v1\n\n[1] 0 1 0\n\n\n\nRelation: &gt; &gt;= &lt; &lt;= == != (last two are equals and is not equal to )\n\n\n5 &gt; 4\n\n[1] TRUE\n\n5 &lt;= 4\n\n[1] FALSE\n\n33 == 22\n\n[1] FALSE\n\n33 != 22\n\n[1] TRUE\n\n\n\nLogic: !(not) &(and) |(or)\n\n\n(5 &gt; 6) | (2 &lt; 3)\n\n[1] TRUE\n\n(5 &gt; 6) & (2 &lt; 3)\n\n[1] FALSE\n\n!(5 &gt; 6) & (2 &lt; 3)\n\n[1] TRUE\n\n\n\nSequence: from:to (Colon operator)\n\n\n1:5\n\n[1] 1 2 3 4 5\n\n5:1\n\n[1] 5 4 3 2 1\n\n-1:-5\n\n[1] -1 -2 -3 -4 -5\n\n-1:5\n\n[1] -1  0  1  2  3  4  5"
  },
  {
    "objectID": "assignment/demo-lab-01.html#read-the-csv-file",
    "href": "assignment/demo-lab-01.html#read-the-csv-file",
    "title": "Getting Started with R",
    "section": "Read the csv file",
    "text": "Read the csv file\nMost of the data provided to you are in csv format. In the code chunk below, we use the read_csv() function to load a dataset that is saved in a folder located in the SURE website. In quotations \"file_path\" is the file path where the dataset is located, which in this case is online. However, typically you’ll save csv files locally first and put them in an organized folder to access later.\n\nnba &lt;- read_csv(\"http://www.stat.cmu.edu/cmsac/sure/2022/materials/data/sports/intro_r/nba_2022_player_stats.csv\")\nhead(nba)"
  },
  {
    "objectID": "assignment/demo-lab-01.html#looking-for-help",
    "href": "assignment/demo-lab-01.html#looking-for-help",
    "title": "Getting Started with R",
    "section": "Looking for help",
    "text": "Looking for help\nIf you have any R problem, the best step is to use the help() function (or equivalently the ?). For example, we can find out what the help() function does by typing help(help):\n\nhelp(help)\n\nOr you can use the statement “?” + “function name”, for example:\n\n?help\n\nDouble question marks can lead to a more general search.\n\n??help\n\nYou should ALWAYS consult the R help pages first before attempting to google around for a solution."
  },
  {
    "objectID": "assignment/demo-lab-01.html#exercise",
    "href": "assignment/demo-lab-01.html#exercise",
    "title": "Getting Started with R",
    "section": "Exercise",
    "text": "Exercise\n\nCreate four vectors, v1 and v2 are numeric vectors, v3 is a character vector and v4 is a logic vector. Make sure the length of v1 and v2 are the same. (Hint: a way to check the length is to use the function length())\n\n\n#R code here\n\n\nPreform add, minus, product and division on v1 and v2.\n\n\n#R code here\n\n\nCreate four statements with both relation and logic operators, that 2 of them return TRUE and 2 of them return FALSE.\n\n\n#R code here\n\n\nCreate 2 sequences with length 20, one in an increasing order and the other in a decreasing order.\n\n\n#R code here\n\n\n(SPORTS) Following is the Batting dataset containing historical MLB statistics from the Lahman package (you will need to install it first!). How many of the players are in Double-A league (coded as ‘AA’ in lgID)? How about American League(‘AL’)? Can you neatly summarize the counts for all leagues? (HINT: table())\n\n\nlibrary(Lahman)\ndata(Batting)\n\n#R code here\n\n\n(HEALTH) Following is the gapminder dataset containing health and income outcomes for 184 countries from 1960 to 2016 from the dslabs package. How many of the rows in the dataset are from the Caribbean (coded as ‘Caribbean’ in region)? How about Eastern Europe? Can you neatly summarize the counts for all regions? (HINT: table())\n\n\nlibrary(dslabs)\ndata(gapminder)\n\n#R code here"
  },
  {
    "objectID": "assignment/demo-lab-02.html",
    "href": "assignment/demo-lab-02.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Our data are usually presented as a csv file and after loading a csv file into R studio, we will have a “data frame”. A data frame can be considered a special case of matrix where each column represents a measurement or variable of interest for each observation which correspond to the rows of the dataset. After loading the tidyverse suite of packages, we use the read_csv() function to load the NBA stats dataset (SPORTS) or the heart disease dataset (HEALTH) from the other day:\n\nlibrary(tidyverse)\n\n# SPORTS\nnba_stats &lt;- read_csv(\"./files/nba_stats.csv\")\n\n# HEALTH\nheart_disease &lt;- read_csv(\"./files/heart_disease.csv\")\n\nBy default, read_csv() reads in the dataset as a tbl (aka tibble) object instead of a data.frame object. You can read about the differences here, but it’s not that meaningful for purposes.\nWe can use the functions head() and tail() to view a sample of the data. Use the head() function to view the first 6 rows, then use the tail() function to view the last 3 rows:\n\n# INSERT CODE HERE\n\nView the dimensions of the data with dim():\n\n# INSERT CODE HERE\n\nQuickly view summary statistics for all variables with the summary() function:\n\n# Uncomment the following code by deleting the # at the front:\n# summary(nba_stats)\n# summary(heart_disease)\n\nView the data structure types with str():\n\n# str(nba_stats)\n# str(heart_disease)\n\nWhat’s the difference between the output from the two functions?"
  },
  {
    "objectID": "assignment/demo-lab-02.html#read-and-preview-data",
    "href": "assignment/demo-lab-02.html#read-and-preview-data",
    "title": "Data Wrangling",
    "section": "",
    "text": "Our data are usually presented as a csv file and after loading a csv file into R studio, we will have a “data frame”. A data frame can be considered a special case of matrix where each column represents a measurement or variable of interest for each observation which correspond to the rows of the dataset. After loading the tidyverse suite of packages, we use the read_csv() function to load the NBA stats dataset (SPORTS) or the heart disease dataset (HEALTH) from the other day:\n\nlibrary(tidyverse)\n\n# SPORTS\nnba_stats &lt;- read_csv(\"./files/nba_stats.csv\")\n\n# HEALTH\nheart_disease &lt;- read_csv(\"./files/heart_disease.csv\")\n\nBy default, read_csv() reads in the dataset as a tbl (aka tibble) object instead of a data.frame object. You can read about the differences here, but it’s not that meaningful for purposes.\nWe can use the functions head() and tail() to view a sample of the data. Use the head() function to view the first 6 rows, then use the tail() function to view the last 3 rows:\n\n# INSERT CODE HERE\n\nView the dimensions of the data with dim():\n\n# INSERT CODE HERE\n\nQuickly view summary statistics for all variables with the summary() function:\n\n# Uncomment the following code by deleting the # at the front:\n# summary(nba_stats)\n# summary(heart_disease)\n\nView the data structure types with str():\n\n# str(nba_stats)\n# str(heart_disease)\n\nWhat’s the difference between the output from the two functions?"
  },
  {
    "objectID": "assignment/demo-lab-02.html#data-manipulation-with-dplyr",
    "href": "assignment/demo-lab-02.html#data-manipulation-with-dplyr",
    "title": "Data Wrangling",
    "section": "Data manipulation with dplyr",
    "text": "Data manipulation with dplyr\nAn easier way to manipulate the data frame is through the dplyr package, which is in the tidyverse suite of packages. The operations we can do include: selecting specific columns, filtering for rows, re-ordering rows, adding new columns and summarizing data. The “split-apply-combine” concept can be achieved by dplyr.\n\nSelecting columns with select()\nThe function select() can be use to select certain column with the column names.\n\n(SPORTS)\nFirst create a new table called nba_stats_pg that only contains the player and games columns:\n\n# INSERT CODE HERE\n\nTo select all the columns except a specific column, use the - (subtraction) operator. For example, view the output from uncommenting the following line of code:\n\n# head(select(nba_stats, -player))\n\nTo select a range of columns by name (that are in consecutive order), use the : (colon) operator. For example, view the output from uncommenting the following line of code:\n\n#head(select(nba_stats, player:games))\n\nTo select all columns that start with certain character strings, use the function starts_with(). Ohter matching options are:\n\nends_with() = Select columns that end with a character string\ncontains() = Select columns that contain a character string\nmatches() = Select columns that match a regular expression\none_of() = Select columns names that are from a group of names\n\n\n# Uncomment the following lines of code\n#head(select(nba_stats, starts_with(\"three\")))\n#head(select(nba_stats, contains(\"throw\")))\n\n\n\n(HEALTH)\nFirst create a new table called heart_disease_ad that only contains the Age and Drugs columns:\n\n# INSERT CODE HERE\n\nTo select all the columns except a specific column, use the - (subtraction) operator. For example, view the output from uncommenting the following line of code:\n\n# head(select(heart_disease, -Interventions))\n\nTo select a range of columns by name (that are in consecutive order), use the : (colon) operator. For example, view the output from uncommenting the following line of code:\n\n#head(select(heart_disease, Drugs:Duration))\n\nTo select all columns that start with certain character strings, use the function starts_with(). Ohter matching options are:\n\nends_with() = Select columns that end with a character string\ncontains() = Select columns that contain a character string\nmatches() = Select columns that match a regular expression\none_of() = Select columns names that are from a group of names\n\n\n# Uncomment the following lines of code\n#head(select(heart_disease, starts_with(\"Com\")))\n#head(select(heart_disease, contains(\"er\")))\n\n\n\n\nSelecting rows using filter()\n\n(SPORTS)\nWe can also select the rows/observations that satisfy certain criteria. Try selecting the rows with more than 500 assists:\n\n# INSERT CODE HERE\n\nWe can also filter on mutiple criteria. Select rows with age above 30 and the team is either “HOU” or “GSW”:\n\n# INSERT CODE HERE\n\n\n\n(HEALTH)\nWe can also select the rows/observations that satisfy certain criteria. Try selecting the rows with more than 500 assists:\n\n# INSERT CODE HERE\n\nWe can also filter on mutiple criteria. Select rows with Age above 60 and the gender is ‘Male’:\n\n# INSERT CODE HERE\n\n\n\n\nArrange or re-order rows using arrange()\nTo arrange the data frame by a specific order we need to use the function arrange(). The default is by increasing order and a negative operator will provide the decreasing order.\n\n(SPORTS)\nFirst arrange the nba_stats table by personal_fouls in ascending order:\n\n# INSERT CODE HERE\n\nNext by descending order:\n\n# INSERT CODE HERE\n\nTry combining a pipeline of select(), filter(), and arrange() steps together with the %&gt;% operator by:\n\nSelecting the player, team, age, and games columns,\nFilter to select only rows with games above 50,\nSort by age in descending order\n\n\n# INSERT CODE HERE\n\n\n\n(HEALTH)\nFirst arrange the heart_disease table by Duration in ascending order:\n\n# INSERT CODE HERE\n\nNext by descending order:\n\n# INSERT CODE HERE\n\nTry combining a pipeline of select(), filter(), and arrange() steps together with the %&gt;% operator by:\n\nSelecting the Age, Cost, ERVisit, and Duration columns,\nFilter to select only rows with Age above 60,\nSort by Duration in descending order\n\n\n# INSERT CODE HERE\n\n\n\n\nCreate new columns using mutate()\nSometimes the data does not include the variable that we are interested in and we need to manipulate the current variables to add new variables into the data frame.\n\n(SPORTS)\nCreate a new column fouls_per_game by taking the personal_fouls and dividing by games (reassign this output to the nba_stats table following the commented code chunk so this column is added to the table):\n\n# nba_stats &lt;- nba_stats %&gt;%\n#   mutate(INSERT CODE HERE)\n\n\n\n(HEALTH)\nCreate a new column cost_per_day by taking the Cost and dividing by Duration (reassign this output to the heart_disease table following the commented code chunk so this column is added to the table):\n\n# heart_disease &lt;- heart_disease %&gt;%\n#   mutate(INSERT CODE HERE)\n\n\n\n\nCreate summaries of the data with summarize()\nTo create summary statistics for a given column in the data frame, we can use summarize() function.\n\n(SPORTS)\nCompute the mean, min, and max number of assists:\n\n# INSERT CODE HERE\n\nThe advantage of summarize is more obvious if we combine it with the group_by(), the group operators. Since players at the different position tend to have very different statistics, first group_by() position and then compute the same summary statistics:\n\n# INSERT CODE HERE\n\n\n\n(HEALTH)\nCompute the mean, min, and max number of Cost:\n\n# INSERT CODE HERE\n\nThe advantage of summarize is more obvious if we combine it with the group_by(), the group operators. Try to group_by() the Gender column first and then compute the same summary statistics:\n\n# INSERT CODE HERE"
  },
  {
    "objectID": "assignment/demo-lab-03.html",
    "href": "assignment/demo-lab-03.html",
    "title": "Data visualization practice with ggplot",
    "section": "",
    "text": "Let’s start again by reading in the data from last lab using the read_csv() function after loading the tidyverse:\n\nlibrary(tidyverse)\n\n# SPORTS\nnba_stats &lt;- read_csv(\"https://shorturl.at/eDL02\")\n\n# HEALTH\nheart_disease &lt;- read_csv(\"https://shorturl.at/borZ7\")\n\nThe NBA dataset contains information about players from the 2022 season.\nThe heart disease dataset was collected by a health insurance company gathering information on subscribers who had claims resulting from ischemic (coronary) heart disease. The dataset contains total costs and types of services for one year. The variables in this dataset include:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nCost\nTotal cost of subscriber claims\n\n\nAge\nAge of claimant\n\n\nGender\nGender of claimant\n\n\nInterventions\nNumber of interventions / procedures given to patient\n\n\nDrugs\nFactor describing number of drugs prescribed to patient\n\n\nERVisit\nNumber of ER visits\n\n\nComplications\nFactor describing number of complications experienced by the patient\n\n\nComorbidities\nNumber of comorbidities the patient had\n\n\nDuration\nDuration of treatment\n\n\nid\nIndex variable"
  },
  {
    "objectID": "assignment/demo-lab-03.html#read-in-data",
    "href": "assignment/demo-lab-03.html#read-in-data",
    "title": "Data visualization practice with ggplot",
    "section": "",
    "text": "Let’s start again by reading in the data from last lab using the read_csv() function after loading the tidyverse:\n\nlibrary(tidyverse)\n\n# SPORTS\nnba_stats &lt;- read_csv(\"https://shorturl.at/eDL02\")\n\n# HEALTH\nheart_disease &lt;- read_csv(\"https://shorturl.at/borZ7\")\n\nThe NBA dataset contains information about players from the 2022 season.\nThe heart disease dataset was collected by a health insurance company gathering information on subscribers who had claims resulting from ischemic (coronary) heart disease. The dataset contains total costs and types of services for one year. The variables in this dataset include:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nCost\nTotal cost of subscriber claims\n\n\nAge\nAge of claimant\n\n\nGender\nGender of claimant\n\n\nInterventions\nNumber of interventions / procedures given to patient\n\n\nDrugs\nFactor describing number of drugs prescribed to patient\n\n\nERVisit\nNumber of ER visits\n\n\nComplications\nFactor describing number of complications experienced by the patient\n\n\nComorbidities\nNumber of comorbidities the patient had\n\n\nDuration\nDuration of treatment\n\n\nid\nIndex variable"
  },
  {
    "objectID": "assignment/demo-lab-03.html#peeking-at-the-data",
    "href": "assignment/demo-lab-03.html#peeking-at-the-data",
    "title": "Data visualization practice with ggplot",
    "section": "Peeking at the data",
    "text": "Peeking at the data\nWrite code that displays the column names of your dataset (nba_stats or heart_disease). Also, look at the first six rows of your dataset to get an idea of what these variables look like. Which variables are quantitative, and which are categorical?\n\n# INSERT CODE HERE\n\n\n(SPORTS)\nThe NBA dataset has no indicator variables, so it doesn’t need any further processing at this time. (But feel free to check out the health section to see how we would deal with that)\n\n\n(HEALTH)\nAs it turns out, even though Drugs and Complications appear to be quantitative - they are actually categorical variables. Specifically, Drugs represents the categorized number of drugs prescribed: 0 if none, 1 if one, 2 if more than one; Complications indicates whether or not the subscriber had complications: 1 if yes, 0 if no. To address this issue for our plots, we can manually recode the variables as factors. For instance, we can modify the Complications variable using a simple if-else statement:\n\nheart_disease &lt;- heart_disease %&gt;%\n  mutate(Complications = ifelse(Complications == 0, \"No\", \"Yes\"))\n\nThis is a quick fix to the binary indicator variable since, by default, R orders factor variables in alphabetical order. In this case, “No” is before “Yes” because “N” is before “Y”. We may not want variables in alphabetical order however - we will see how to change this in lecture.\nNext, to update the Drugs variable we will use the fct_recode() function which allows us to manually change the labels of a factor variable:\n\nheart_disease &lt;- heart_disease %&gt;%\n  mutate(Drugs = fct_recode(as.factor(Drugs), \n                            \"None\" = \"0\", \"One\" = \"1\", \"More than one\" = \"2\"))\n\nWhy did we have to specify as.factor(Drugs) first then place the numbers in quotation marks?\n\n\n(ALL TOGETHER NOW)"
  },
  {
    "objectID": "assignment/demo-lab-03.html#always-make-a-bar-chart",
    "href": "assignment/demo-lab-03.html#always-make-a-bar-chart",
    "title": "Data visualization practice with ggplot",
    "section": "Always make a bar chart…",
    "text": "Always make a bar chart…\nNow we’ll use the ggplot() function to create a bar plot of one of the categorical variables. To make things easier, we provide the code for you to do this below; just uncomment the code and run it to create the bar plot. In what follows, you must answer some questions about the code and plot.\n\n(SPORTS)\nMake a bar plot of position in the NBA dataset.\n\n# Create the bar plot of position:\n# nba_stats %&gt;%\n#   ggplot(aes(x = position)) +\n#   geom_bar(fill = \"darkblue\") +\n#   labs(title = \"Number of NBA players by position\",\n#        x = \"Position\", y = \"Number of players\",\n#        caption = \"Source: Basketball-Reference.com\")\n\n\n\n(HEALTH)\nMake a bar plot of Drugs in the heart disease dataset.\n\n# Create the bar plot of Drugs:\n# heart_disease %&gt;%\n#   ggplot(aes(x = Drugs)) +\n#   geom_bar(fill = \"darkblue\") +\n#   labs(title = \"Number of patients by number of drugs\",\n#        x = \"Number of drugs\", y = \"Number of patients\")\n\n\n\n(ALL TOGETHER NOW)\nNow, answer the following questions about the code and plot:\n\nIn general, ggplot() code takes the following format: ggplot(blank1, aes(x = blank2)). Looking at the above code, what kind of R object should blank1 be, and what should blank2 be?\nWhat do you think the line geom_bar(fill = \"darkblue\") does?\nWhat do you think the remaining lines of code do (contained in labs())?"
  },
  {
    "objectID": "assignment/demo-lab-03.html#more-area-plots-but-bar-plots-are-better",
    "href": "assignment/demo-lab-03.html#more-area-plots-but-bar-plots-are-better",
    "title": "Data visualization practice with ggplot",
    "section": "More area plots (but bar plots are better!)",
    "text": "More area plots (but bar plots are better!)\nNow we’ll make a few other area plots:\n\nspine chart\npie chart\nrose diagram\n\nYour goal for this part is to create each of these plots. These plots can be created by copy-and-pasting the bar plot code from above and modifying it slightly. Follow these directions to create each of these plots:\n\nspine chart: First, copy-and-paste the bar plot code from above. Then, delete the fill = \"darkblue\" within geom_bar(). Finally, within ggplot(), replace aes(x = position) with aes(x = \"\", fill = position) (SPORTS), or replace aes(x = Drugs) with aes(x = \"\", fill = Drugs) (HEALTH). Also, change the labels in labs() if necessary.\n\n\n# PUT YOUR SPINE CHART CODE HERE\n\n\npie chart: First, copy-and-paste the spine chart code you just made. Then, after geom_bar(), “add” coord_polar(\"y\"). Be sure to put plus signs before and after coord_polar(\"y\"). Also, change the labels in labs() if necessary.\n\n\n# PUT YOUR PIE CHART CODE HERE\n\n\nrose diagram: First, copy-and-paste your original bar plot code. Then, after geom_bar(fill = \"darkblue\"), “add” coord_polar() + scale_y_sqrt(). Be sure to put plus signs before and after coord_polar() + scale_y_sqrt(). Also, change the labels in labs() if necessary. After you make the rose diagram: In 1-2 sentences, what do you think scale_y_sqrt() does, and what is a benefit to including scale_y_sqrt() when making the rose diagram?\n\n\n# PUT YOUR ROSE DIAGRAM CODE HERE"
  },
  {
    "objectID": "assignment/demo-lab-03.html#notes-on-colors-in-plots",
    "href": "assignment/demo-lab-03.html#notes-on-colors-in-plots",
    "title": "Data visualization practice with ggplot",
    "section": "Notes on colors in plots",
    "text": "Notes on colors in plots\nThree types of color scales to work with:\n\nQualitative: distinguishing discrete items that don’t have an order (nominal categorical). Colors should be distinct and equal with none standing out unless otherwise desired for emphasis.\n\n\nDo NOT use a discrete scale on a continuous variable\n\n\nSequential: when data values are mapped to one shade, e.g., for an ordered categorical variable or low to high continuous variable\n\n\nDo NOT use a sequential scale on an unordered variable\n\n\nDivergent: think of it as two sequential scales with a natural midpoint midpoint could represent 0 (assuming +/- values) or 50% if your data spans the full scale\n\n\nDo NOT use a divergent scale on data without natural midpoint\n\n\nOptions for ggplot2 colors\nThe default color scheme is pretty bad to put it bluntly, but ggplot2 has ColorBrewer built in which makes it easy to customize your color scales.\n\n(SPORTS)\nFor instance, we can make a scatterplot with three_pointers on the y-axis and offensive_rebounds on the x-axis and using the geom_point() layer with each point colored by position:\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = position)) +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Position\") +\n  theme_bw()\n\n\n\n\nWhat does alpha change? We can change the color plot for this plot using scale_color_brewer() function:\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = position)) +\n  geom_point(alpha = 0.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Position\") +\n  theme_bw()\n\n\n\n\n\n\n(HEALTH)\nAlternatively, we can make a scatterplot with Cost on the y-axis and Duration on the x-axis and using the geom_point() layer with each point colored by Drugs:\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Drugs)) +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Number of drugs\") +\n  theme_bw()\n\n\n\n\nWhat does alpha change? We can change the color plot for this plot using scale_color_brewer() function:\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Drugs)) +\n  geom_point(alpha = 0.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Number of drugs\") +\n  theme_bw()\n\n\n\n\n\n\n(ALL TOGETHER NOW)\nWhich do you prefer, the default palette or this new one? You can check out more color palettes here.\nSomething you should keep in mind is to pick a color-blind friendly palette. One simple way to do this is by using the ggthemes package (you need to install it first before running this code!) which has color-blind friendly palettes included:\n\n\n(SPORTS)\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = position)) +\n  geom_point(alpha = 0.5) +\n  # Notice I did not use library(ggthemes) to do this... just '::'\n  ggthemes::scale_color_colorblind() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Position\") +\n  theme_bw()\n\n\n\n\nIn terms of displaying color from low to high, the viridis scales are excellent choices (and are also color-blind friendly!). For instance, we can map another continuous variable (minutes_played) to the color:\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_bw()\n\n\n\n\n\n\n(HEALTH)\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Drugs)) +\n  geom_point(alpha = 0.5) +\n  # Notice I did not use library(ggthemes) to do this... just '::'\n  ggthemes::scale_color_colorblind() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Number of drugs\") +\n  theme_bw()\n\n\n\n\nIn terms of displaying color from low to high, the viridis scales are excellent choices (and are also color-blind friendly!). For instance, we can map another quantitative variable (Interventions) to the color:\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_bw()\n\n\n\n\n\n\n(ALL TOGETHER NOW)\nWhat does this reveal about the plot? What happens if you delete scale_color_viridis_c() + from above? Which do you prefer?"
  },
  {
    "objectID": "assignment/demo-lab-03.html#notes-on-themes",
    "href": "assignment/demo-lab-03.html#notes-on-themes",
    "title": "Data visualization practice with ggplot",
    "section": "Notes on themes",
    "text": "Notes on themes\nYou might have noticed above have various changes to the theme of plots for customization. You will constantly be changing the theme of your plots to optimize the display. Fortunately, there are a number of built-in themes you can use to start with rather than the default theme_gray():\n\n(SPORTS)\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_gray()\n\n\n\n\nFor instance, Prof Yurko prefers theme_bw():\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_bw()\n\n\n\n\nThere are options such as theme_minimal():\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_minimal()\n\n\n\n\nor theme_classic():\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_classic()\n\n\n\n\nThere are also packages with popular themes, such as the ggthemes package which includes, for example, theme_economist():\n\nlibrary(ggthemes)\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_economist()\n\n\n\n\nand theme_fivethirtyeight() to name a couple:\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       color = \"Minutes played\") +\n  theme_fivethirtyeight()\n\n\n\n\nWith any theme you have picked, you can then modify specific components directly using the theme() layer. There are many aspects of the plot’s theme to modify, such as my decision to move the legend to the bottom of the figure, drop the legend title, and increase the font size for the y-axis:\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       title = \"Joint distribution of three-pointers and offensive rebounds\",\n       subtitle = \"NBA statistics from 2021-2022 season\",\n       color = \"Minutes played\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text.y = element_text(size = 14),\n        axis.text.x = element_text(size = 6))\n\n\n\n\n\n\n(HEALTH)\nStarting with the default theme_gray():\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_gray()\n\n\n\n\nMany other themes are out there. For instance, Prof Yurko prefers theme_bw():\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_bw()\n\n\n\n\nThere are options such as theme_minimal():\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_minimal()\n\n\n\n\nor theme_classic():\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_classic()\n\n\n\n\nThere are also packages with popular themes, such as the ggthemes package which includes, for example, theme_economist():\n\nlibrary(ggthemes)\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_economist()\n\n\n\n\nand theme_fivethirtyeight() to name a couple:\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       color = \"Interventions\") +\n  theme_fivethirtyeight()\n\n\n\n\nWith any theme you have picked, you can then modify specific components directly using the theme() layer. There are many aspects of the plot’s theme to modify, such as my decision to move the legend to the bottom of the figure, drop the legend title, and increase the font size for the y-axis:\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       title = \"Joint distribution of patients' duration and cost\",\n       color = \"Interventions\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text.y = element_text(size = 14),\n        axis.text.x = element_text(size = 6))\n\n\n\n\n\n\n(ALL TOGETHER NOW)\nIf you’re tired of explicitly customizing every plot in the same way all the time, then you should make a custom theme. It’s quite easy to make a custom theme for ggplot2 and of course there are an incredible number of ways to customize your theme. In the code chunk, I modify the theme_bw() theme using the %+replace% argument to make my new theme named my_theme() - which is stored as a function:\n\nmy_theme &lt;- function () {\n  # Start with the base font size\n  theme_bw(base_size = 10) %+replace%\n    theme(\n      panel.background  = element_blank(),\n      plot.background = element_rect(fill = \"transparent\", color = NA), \n      legend.position = \"bottom\",\n      legend.background = element_rect(fill = \"transparent\", color = NA),\n      legend.key = element_rect(fill = \"transparent\", color = NA),\n      axis.ticks = element_blank(),\n      panel.grid.major = element_line(color = \"grey90\", size = 0.3), \n      panel.grid.minor = element_blank(),\n      plot.title = element_text(size = 18, \n                                hjust = 0, vjust = 0.5, \n                                face = \"bold\", \n                                margin = margin(b = 0.2, unit = \"cm\")),\n      plot.subtitle = element_text(size = 12, hjust = 0, \n                                   vjust = 0.5, \n                                   margin = margin(b = 0.2, unit = \"cm\")),\n      plot.caption = element_text(size = 7, hjust = 1,\n                                  face = \"italic\", \n                                  margin = margin(t = 0.1, unit = \"cm\")),\n      axis.text.x = element_text(size = 13),\n      axis.text.y = element_text(size = 13)\n    )\n}\n\nNow I can go ahead and make my plot from before with this theme:\n\n\n(SPORTS)\n\nnba_stats %&gt;%\n  ggplot(aes(x = offensive_rebounds, y = three_pointers,\n             color = minutes_played)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Offensive rebounds\", y = \"Three-pointers\",\n       title = \"Joint distribution of three-pointers and offensive rebounds\",\n       subtitle = \"NBA statistics from 2021-2022 season\",\n       color = \"Minutes played\") +\n  my_theme()\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n(HEALTH)\n\nheart_disease %&gt;%\n  ggplot(aes(x = Duration, y = Cost,\n             color = Interventions)) +\n  geom_point(alpha = 0.5) +\n  scale_color_viridis_c() +\n  labs(x = \"Duration\", y = \"Cost\",\n       title = \"Joint distribution of patients' duration and cost\",\n       color = \"Interventions\") +\n  my_theme()"
  },
  {
    "objectID": "assignment/demo-lab-04.html",
    "href": "assignment/demo-lab-04.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "This lab will be slightly more open-ended, giving you a sense of how you might choose to do exploratory data analysis as part of a research project. Remember to emphasize the exploratory aspect here! Feel free to try as many combinations as you like for each of the prompts."
  },
  {
    "objectID": "assignment/demo-lab-04.html#read-in-data",
    "href": "assignment/demo-lab-04.html#read-in-data",
    "title": "Exploratory Data Analysis",
    "section": "Read in data",
    "text": "Read in data\nLet’s start again by reading in the data using the read_csv() function after loading the tidyverse. The (SPORTS) group will be using historical data about MLB teams, and the (HEALTH) group will be using data from the CDC about maternal health care disparities:\n\nlibrary(tidyverse)\n\n# SPORTS\nmlb_teams &lt;- read.csv(\"https://shorturl.at/KMX05\")\n\n# HEALTH\nmaternal_health &lt;- read_csv(\"https://shorturl.at/gmCFK\")\n\nA brief description of these datasets:\n\n(SPORTS)\nThis dataset contains information about MLB teams from each season from 1871 to 2018. Each row is an observation of one team for one season, including their overall performance and season stats like hits and hits allowed.\n\n\n(HEALTH)\nThe Maternal Health dataset is a bit more complicated, which is why we’ll explain it a bit further here: The data come from a CDC program assessing maternal health, and they provide aggregated birth records. Observations are grouped by state and several different conditions that might have affected the mother: pre-pregnancy diabetes, pre-pregnancy hypertension, smoking, and prior births that were deceased at the time of data collection.\nA row represents the number of births with that set of conditions in that state, and the other columns provide averages of different variables among those births. For example, the first row corresponds to births in Alabama where the mother had no prior births now deceased, did smoke, and did have both hypertension and diabetes pre-pregnancy. There were 12 births in this category, and the average age of the mothers was 29.33, and so on."
  },
  {
    "objectID": "assignment/demo-lab-04.html#peeking-at-the-data",
    "href": "assignment/demo-lab-04.html#peeking-at-the-data",
    "title": "Exploratory Data Analysis",
    "section": "Peeking at the data",
    "text": "Peeking at the data\nUse whatever functions you like to get an initial sense of your dataset. What are the variables you have access to? What kinds of data are in each column? Are there any columns that might be more or less useful than others?\n\n# INSERT CODE HERE\n\nNote that some columns may have missing data. You will have to decide how to deal with that. There isn’t always a right answer with this kind of thing."
  },
  {
    "objectID": "assignment/demo-lab-04.html#single-variable-plots",
    "href": "assignment/demo-lab-04.html#single-variable-plots",
    "title": "Exploratory Data Analysis",
    "section": "Single-variable plots",
    "text": "Single-variable plots\nRemember that the general format of a ggplot call is this:\n\nggplot(data = &lt;dataframe&gt;) +\n  geom_function(mapping = aes(&lt;arguments&gt;)) +\n  &lt;other layers&gt;\n\nYou can also pipe the data in from a series of dplyr manipulations, rather than specifying it in the ggplot() call. Similarly, if you will be using the same arguments to aes() for several different geom_function() calls, you can put that mapping statement in the original ggplot() call. Additional layers can be added on top of these functions: labeling axes, specifying scales, modifying the theme.\nNow, at this point you’ve seen many types of visualizations.\nCreate a visualization of one of the quantitative variables in your dataset (and feel free to rinse and repeat here. Explore that data!).\n\n# INSERT CODE HERE\n\nWhen you’re doing EDA, it’s fine to leave your graphs “ugly” if you’re just messing around, seeing how things look (I promise, I do not add titles to plots when I’m first checking out my data). However, as soon as you get to the point of showing a plot to someone else, you should clean it up. Give it a title, make sure the axis labels are meaningful (and neat… underscores = BAD!). Modify the theme, and maybe even the color palette if you want to get fancy.\nModify your code from above to make a plot that is presentable:\n\n# INSERT CODE HERE\n\nOk, now you can leave your plots “ugly” for the rest of the lab, if you prefer. Or keep adding labels and stuff, you do you.\nCreate a visualization (or several) of one (or more) of the categorical variables in your dataset. Do some kinds of categorical variables seem to lend themselves better to certain kinds of visualizations rather than others?\n\n# INSERT CODE HERE"
  },
  {
    "objectID": "assignment/demo-lab-04.html#multivariate-plots",
    "href": "assignment/demo-lab-04.html#multivariate-plots",
    "title": "Exploratory Data Analysis",
    "section": "Multivariate plots",
    "text": "Multivariate plots\nOften, EDA is a precursor to another kind of analysis, like modeling with linear regression. So at this point you might want to get a sense of which variables might be related to each other, or to some outcome of interest.\nCreate a visualization of two of your quantitative variables together.\n\n# INSERT CODE HERE\n\nCreate a visualization with one categorical and one quantitative variable together.\n\n# INSERT CODE HERE\n\nCreate a visualization with two categorical variables.\n\n# INSERT CODE HERE\n\nMake a plot involving more than two variables (e.g. a scatterplot colored by a third variable, a set of faceted histograms or bar charts. Go wild).\n\n# INSERT CODE HERE\n\nI’m sure I’ve mentioned this in lecture by this point, but my favorite resources ever are the RStudio cheatsheets– I literally have the ones for ggplot, dplyr, and forcats printed and hanging in sheet protectors at my desk at all times, and I refer back to them all the time. Access the data visualization cheat sheet here, but also note that there are tons of other cheatsheets in that repository as well.\nPick some visualization or feature of ggplot2 that we have not yet covered in lecture or labs and try it out here.\n\n# INSERT CODE HERE\n\nI should also note that there are some EDA techniques that do not involve ggplot2 that are still really useful.\nAs I mentioned before, going into regression analysis you want to have a sense of which of your variables are related to each other– both to get a good model for your outcome variable and also to deal with any issues of multicollinearity. One quick way to look at all your (quantitative) variables at once is to use a pairs plot. You can do this in base R, but it’s a bit nicer using the package GGally (you’ll need to install it first). We can use the ggpairs function: first, select only the quantitative variables in your dataset, then pipe that to ggpairs()\n\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n# INSERT CODE HERE\n\nA word of warning: pairs plots can get really overwhelming, really fast. The more variables you have the more there is to look at in this kind of plot. Honestly, I would not recommend using a pairs plot in any kind of forward-facing material (report, slides, etc.), but they can be a convenient one-step way to check for relationships on your own.\nAnother useful visualization for this kind of thing is a correlation plot, which is similar to the pairs plot but exclusively shows the correlations, their directions, and their magnitude. There’s a nice package called corrplot that does this, but it’s a bit more involved. You can read about how to use it here (and this will give you a bit of practice using R documentation and vignettes to figure out how to use new stuff on your own. Google is your friend.)\n\n# OPTIONAL: CORRPLOT"
  },
  {
    "objectID": "assignment/demo-lab-04.html#wrapping-up",
    "href": "assignment/demo-lab-04.html#wrapping-up",
    "title": "Exploratory Data Analysis",
    "section": "Wrapping up",
    "text": "Wrapping up\nA couple more things: while much of the EDA we’ve done so far has been with an eye towards further analysis later, it is important to note that sometimes you might have a question that can be answered directly with data visualization. EDA can often actually be the end in and of itself. Visualizations can be used to support or refute hypotheses just as much as actual modeling can.\nAlso, sometimes we will actually want to save a plot to a file rather than just having it in RStudio and/or taking a screenshot (which tbh is my usual way of doing things). To do this, you just use the function ggsave: build your plot, assign it to a variable, and then use that variable as an argument to the function.\n\nmy_plot &lt;- ggplot() # make your plot here\n\nggsave(filename = \"myplot.pdf\", plot = my_plot, width = 5, height = 3)\n\nYou can specify the name and path for saving the file, as well as the file type and the size of the image."
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "There are two main forms of assignments in the SURE 2023 program, namely:\nSome additional details on both are provided below."
  },
  {
    "objectID": "assignment/index.html#demo-labs",
    "href": "assignment/index.html#demo-labs",
    "title": "Assignments",
    "section": "Demo-labs",
    "text": "Demo-labs\nWe also provide you demo-lab materials for you to test out your understanding of the course content. They are usually released once or twice a week, as per the schedule. Completing these demo-labs is strongly recommended to help you reinforce the material. There is no grading involved here, just learning. So don’t hesitate to reach out to your fellow peers, TA Advisors, and course instructors for help.\n\nViewing demo labs (in your browser)\nYou can view all demo lab materials in your browser (e.g., Chrome/Firefox) by navigating the links in the left sidebar, under the ‘Demo Lab’ dropdown header, or via the schedule.\n\n\nDownloading demo labs (on your laptop)\nYou can also download the RMarkdown (.Rmd) demo-lab files using the convenient links below:\n\n\n\n\n\n\nDownload Demo Lab 1 (Intro to R):\n demo-lab-01.Rmd \nDownload Demo Lab 2 (data wrangling with dplyr):\n demo-lab-02.Rmd   demo-lab-02-supp.zip \nDownload EDA Mini Project 1 (Requirements and Data):\n mini-project-01.Rmd \nDownload Demo Lab 3 (Data visualization practice with ggplot):\n demo-lab-03.Rmd \nDownload Demo Lab 4 (Exploratory Data Analysis (Case Studies)):\n demo-lab-04.Rmd"
  },
  {
    "objectID": "assignment/index.html#research-project-deliverables",
    "href": "assignment/index.html#research-project-deliverables",
    "title": "Assignments",
    "section": "Research project deliverables",
    "text": "Research project deliverables\nAs noted in our syllabus and schedule the only deliverables you have are your final (Optum or CMSAC) research project report, poster, and presentation.\n\n\n\n\n\n\nResearch project deliverables\n\n\n\nWe reemphasize that the research project won’t be formally graded. However your three research deliverables will be presented by you to various important (executive) stakeholders in healthcare (Optum) and the sports (CMSAC) data science community.\nSo it is in your best interest to put your best foot forward, since it will be of great benefit for your future data science career!\n\n\nYou can view all assignment materials by navigating the links in the left sidebar, or via the schedule."
  },
  {
    "objectID": "assignment/mini-project-01.html",
    "href": "assignment/mini-project-01.html",
    "title": "EDA Mini-Project Requirements and Data",
    "section": "",
    "text": "This mini-project will begin on Thursday, June 8 and conclude with a 10 minute (maximum) presentation one week later on Friday, June 12. Students will be paired into groups of two or three and randomly assigned one of six sports datasets. The goal of this project is to practice understanding the data structure of a dataset, generating hypotheses and using exploratory data analysis and data visualization to attempt to answer these hypotheses."
  },
  {
    "objectID": "assignment/mini-project-01.html#data",
    "href": "assignment/mini-project-01.html#data",
    "title": "EDA Mini-Project Requirements and Data",
    "section": "Data",
    "text": "Data\n\nEDA projects data overview\nThere are six different datasets for the EDA projects (linked here):\n\nNBA Player Statistics\nWNBA Shots\nNFL Team Statistics\nNHL Shots\nNWSL Team Statistics\nWTA Grand Slam Matches\n\nThese datasets were curated by Ron Yurko as part of the SCORE project, and his description of each dataset can be found below.\n\n\nNBA Player Statistics\nThe National Basketball Association (NBA) is the top men’s professional basketball league in the world. While players have predefined positions, the sport is becoming increasingly positionless - with centers attempting more three point shots and guards driving the ball inside to dunk. With this dataset, you can explore clustering NBA players based on various types of statistics and compare your players labels to the predefined positions.\nThis dataset contains statistics about 812 player-team stints for during the 2021-2022 NBA regular season. For players that played for \\(T\\) teams during the season (due to trade), there are \\(T+1\\) rows with one row for their performance with each of the \\(T\\) teams and another row indicating their total performance (where tm = TOT) across the full season regardless of team. The counting stats are reported on a per 100 team possessions scale, to normalize for playing time differences.\nThe data was collected using the ballr package in R., which gathers data from basketball-reference.com.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nplayer\nName of player\n\n\npos\nPlayer’s designated position\n\n\nage\nPlayer’s age on February 1st of the season\n\n\ntm\nName of team\n\n\ng\nNumber of games\n\n\ngs\nNumber of games started\n\n\nmp\nNumber of minutes played\n\n\nfg\nField goals per 100 team possessions\n\n\nfga\nField goal attempts per 100 team possessions\n\n\nfgpercent\nField goal percentage\n\n\nx3p\n3 point field goals per 100 team possessions\n\n\nx3pa\n3 point field goal attempts per 100 team possessions\n\n\nx3ppercent\n3 point field goal percentage\n\n\nx2p\n2 point field goals per 100 team possessions\n\n\nx2pa\n2 point field goal attempts per 100 team possessions\n\n\nx2ppercent\n2 point field goal percentage\n\n\nft\nFree throws per 100 team possessions\n\n\nfta\nFree throw attempts per 100 team possessions\n\n\nftpercent\nFree throw percentage\n\n\norb\nOffensive rebounds per 100 team possessions\n\n\ndrb\nDefensive rebounds per 100 team possessions\n\n\ntrb\nTotal rebounds per 100 team possessions\n\n\nast\nAssists per 100 team possessions\n\n\nstl\nSteals per 100 team possessions\n\n\nblk\nBlocks per 100 team possessions\n\n\ntov\nTurnovers per 100 team possessions\n\n\npf\nPersonal fouls per 100 team possessions\n\n\npts\nPoints per 100 team possessions\n\n\nortg\nOffensive Rating - an estimate of points produced per 100 possessions scale\n\n\ndrtg\nDefensive Rating - an estimate of points allowed per 100 possessions scale\n\n\n\n\n\nWNBA Shots\nThe Women’s National Basketball Association (WNBA) is the top professional women’s basketball league in the world. The league records every shot players take along with contextual information about the shot such as its location, a description of the shot type, as well as the outcome. With this dataset, you can predict the success of each shot attempt to compute the expected value of shot types and compare team decision making.\nThis dataset contains information about 41,497 shots during the 2021-2022 WNBA season.\nThe data was collected using the wehoop package in R.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique integer ID for each WNBA game\n\n\ngame_play_number\nInteger indicating the recorded play number for the shot attempt, where 1 indicates the first play of the game\n\n\ndesc\nString detailed description of shot attempt\n\n\nshot_type\nString description of the shot type (e.g., dunk, layup, jump shot, etc.)\n\n\nmade_shot\nBoolean denoting if the shot was made (TRUE) or not (FALSE)\n\n\nshot_value\nNumeric value of the shot outcome (0 for shots that were not made, and a positive value for made shots)\n\n\ncoordinate_x\nHorizontal location in feet of shot attempt where the hoop would be located at 25 feet\n\n\ncoordinate_y\nVertical location in feet of shot attempt with respect to the target hoop (the hoop should be a little in front of 0 but the coordinate system is not exact)\n\n\nshooting_team\nString name of the team taking the shot\n\n\nhome_name\nString name of the home team\n\n\naway_name\nString name of the away team\n\n\nhome_score\nInteger value of the home team score after the shot\n\n\naway_score\nInteger value of the away team score after the shot\n\n\nqtr\nInteger denoting the quarter/period in the game\n\n\nquarter_seconds_remaining\nNumeric integer value for number of seconds remaining in quarter/period\n\n\ngame_seconds_remaining\nNumeric integer value for number of seconds remaining in game\n\n\n\n\n\nNFL Team Statistics\nThe National Football League (NFL) is the top professional American football league in the world. While a team’s record ultimately determines whether or not they make the playoffs, their score differential (points for - points against) is often a better indicator of a team’s ability. But what aspects of a team’s performance are related to their point differential? Is passing more important than rushing? What about offense in comparison to defense? The NFL records a variety of statistics, and the public NFL analytics community have developed advanced metrics such as expected points added (EPA) that provide deeper insight into a team’s performance. With this dataset of statistics dating back to 1999, you can explore variation between teams since as well as which types of statistics are relevant predictor variables of record and point differential.\nThis dataset contains statistics about the regular season performance for each NFL team from 1999 to 2022 team. The data was collected using the nflreadr package in R.\nEach row in the dataset corresponds to a single NFL team in a single regular season. There are a total of 765 team-seasons, with 56 total columns. The column names are organized below by the type of information they contain, with the first set of columns being self-explanatory:\n\n\n\nVariable\nDescription\n\n\n\n\nseason\nRegular season year of team’s statistics\n\n\nteam\nNFL team three letter abbreviation\n\n\n\nThere are also columns with season level outcomes:\n\n\n\nVariable\nDescription\n\n\n\n\npoints_score\nTotal number of points scored by the team\n\n\npoints_allowed\nTotal number of points allowed by the team\n\n\nwins\nNumber of games the team won\n\n\nlosses\nNumber of games the team lost\n\n\nties\nNumber of games the team tied\n\n\nscore_differential\npoints scored - points allowed\n\n\n\nThere are also several columns corresponding to offensive and defensive summaries of the team’s performance in the season separated by play type (either pass or run):\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\noffense/defense_completion_percentage\nPassing completion percentage either for (offense) or against (defense)\n\n\noffense/defense_total_yards_gained_pass/run\nTotal number of yards gained (offense) or allowed (defense) by play type (pass or run)\n\n\noffense/defense_ave_yards_gained_pass/run\nAverage number of yards gained (offense) or allowed (defense) per play by play type (pass or run)\n\n\noffense/defense_total_air_yards\nTotal number of air yards gained (offense) or allowed (defense), where air yards correspond to perpendicular yards traveled from the line of scrimmage to location of catch for passing plays\n\n\noffense/defense_ave_air_yards\nAverage number of air yards gained (offense) or allowed (defense) per passing play\n\n\noffense/defense_total_yac\nTotal number of yards after catch gained (offense) or allowed (defense)\n\n\noffense/defense_ave_yac\nAverage number of yards after catch gained (offense) or allowed (defense) per passing play\n\n\noffense/defense_n_plays_pass/run\nTotal number of plays by the team (offense) or against (defense) by play type (pass or run)\n\n\noffense/defense_n_interceptions\nTotal number of interceptions thrown (offense) or caught (defense)\n\n\noffense/defense/n_fumbles_lost_pass/run\nTotal number of fumbles lost (offense) or forced (defense) by play type (pass or run)\n\n\noffense/defense_total_epa_pass/run\nTotal expected points added (offense) or allowed (defense) by play type (pass or run)\n\n\noffense/defense_ave_epa_pass/run\nAverage expected points added (offense) or allowed (defense) per play by play type (pass or run)\n\n\noffense/defense_total_wpa_pass/run\nTotal win probability added (offense) or allowed (defense) by play type (pass or run)\n\n\noffense/defense_ave_wpa_pass/run\nAverage win probability added (offense) or allowed (defense) per play by play type (pass or run)\n\n\noffense/defense_total_epa_pass/run\nTotal expected points added (offense) or allowed (defense) by play type (pass or run)\n\n\noffense/defense_success_rate_pass/run\nProportion of plays with positive expected points added (offense) or allowed (defense) by play type (pass or run)\n\n\n\nThe EPA variables are advanced NFL statistics, conveying how much value a team is adding over the average team in a given situation. It’s on a points scale instead of the typically used yards, because not all yards are created equal in American football (10 yard gain on 3rd and 15 is much less valuable than a 2 yard gain on 4th and 1). For offensive stats the higher the EPA the better, but for defensive stats the lower (more negative) the EPA the better. The WPA variables are similar except they are measuring play value in terms of win probability.\n\n\nNHL Shots\nThe National Hockey League (NHL) is the top professional men’s hockey league in the world. The league records every shot players take along with contextual information about the shot such as its location, the player’s distance and angle to the goal when attempting the shot, as well as the outcome (blocked, missed, or goal). Using this information, the hockey analytics community have developed measures of shot quality known as expected goals. With this dataset, you can create your own expected goals model to predict the shot outcome given relevant features.\nThis dataset contains information about 104,316 shots during the 2021-2022 NHL season.\nThe data was collected using the hockeyR package in R.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ndescription\nString detailed description of event\n\n\nshot_outcome\nString denoting the outcome of the shot, either BLOCKED_SHOT (meaning blocked by a non-goalie), GOAL, MISSED_SHOT (shot that missed the net), or SHOT (shot on net that was saved by a goalie)\n\n\nperiod\nInteger value of the game period\n\n\nperiod_seconds_remaining\nNumeric value of the seconds remaining in the period\n\n\ngame_seconds_remaining\nNumeric value of the seconds remaining in the game; negative for overtime periods\n\n\nhome_score\nInteger value of the home team score after the event\n\n\naway_score\nInteger value of the away team score after the event\n\n\nhome_name\nString name of the home team\n\n\naway_name\nString name of the away team\n\n\nevent_team\nString defining the team taking the shot\n\n\nevent_player_1_name\nString name of the primary event player\n\n\nevent_player_1_type\nString indicator for the role of event_player_1 (typically the shooter)\n\n\nevent_player_2_name\nString name of the secondary event player\n\n\nevent_player_2_type\nString indicator for the role of event_player_2 (blocker, assist, or goalie)\n\n\nstrength_code\nString indicator for game strength: EV (Even), SH (Shorthanded), or PP (Power Play)\n\n\nx_fixed\nNumeric transformed x-coordinate of event in feet, where the home team always shoots to the right, away team to the left\n\n\ny_fixed\nNumeric transformed y-coordinate of event in feet, where the home team always shoots to the right, away team to the left\n\n\nshot_distance\nNumeric distance (in feet) to center of net for unblocked shot events\n\n\nshot_angle\nNumeric angle (in degrees) to center of net for unlocked shot events\n\n\n\n\n\nNWSL Team Statistics\nThe National Women’s Soccer League (NWSL) is the top professional women’s soccer league in the United States. While a team’s record ultimately determines their ranking, goal differential (goals scored - goals conceded) is often a better indicator of a team’s ability. But what aspects of a team’s performance are related to their goal differential? The NWSL records a variety of statistics describing a team’s performance, such as the percentage of time they maintain possession, percentage of shots on target, etc. With this dataset, you can explore variation between teams as well as which statistics are relevant predictor variables of goal differential.\nThis dataset contains statistics about the regular season performance for each NWSL team from 2016 to 2022 (excluding 2020 which was cancelled due to COVID).\nThe data was collected using the nwslR package in R.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nteam_name\nName of NWSL team\n\n\nseason\nRegular season year of team’s statistics\n\n\ngames_played\nNumber of games team played in season\n\n\ngoal_differential\nGoals scored - goals conceded\n\n\ngoals\nNumber of goals scores\n\n\ngoals_conceded\nNumber of goals conceded\n\n\ncross_accuracy\nPercent of crosses that were successful\n\n\ngoal_conversion_pct\nPercent of shots scored\n\n\npass_pct\nPass accuracy\n\n\npass_pct_opposition_half\nPass accuracy in opposition half\n\n\npossession_pct\nPercentage of overall ball possession the team had during the season\n\n\nshot_accuracy\nPercentage of shots on target\n\n\ntackle_success_pct\nPercent of successful tackles\n\n\n\n\n\nWTA Grand Slam Matches\nThe Women’s Tennis Associate (WTA) organizes the top women’s professional tennis tour in the world. Throughout the year, there are four major tournaments yielding the most ranking points, prize money, and fame. These are known as the Grand Slam tournaments, consisting of (in order): Australian Open, French Open (aka Roland Garros), Wimbledon, and the US Open. With this dataset of information about winners and losers in WTA Grand Slam matches from 2018 to 2022, you’ll be able to explore statistics collected during matches and information about the athletes to predict match outcomes.\nThis dataset contains all WTA matches between 2018 and 2022, courtesy of Jeff Sackmann’s famous tennis repository.\nThere are 2,413 rows in this dataset where each row corresponds to a single WTA Grand Slam match. Each row has 38 columns with general information about the matches, as well as columns describing the winner and loser of the matches:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntourney_name\nname of the Grand Slam Tournament (French Open is recorded as ROLAND GARROS)\n\n\nsurface\ntype of court surface\n\n\ntourney_date\neight digits, YYYYMMDD, usually the Monday of the tournament week\n\n\nwinner/loser_seed\nseed of winning/losing player\n\n\nwinner/loser_name\nName of the winning/losing player\n\n\nwinner/loser_hand\nR = right, L = left, U = unknown. For ambidextrous players, this is their serving hand\n\n\nwinner/loser_ht\nheight in centimeters, where available\n\n\nwinner/loser_ioc\nthree-character country code\n\n\nwinner/loser_age\nage, in years, as of the tourney_date\n\n\nscore\nfinal match score\n\n\nround\ntournament round\n\n\nminutes\nmatch length in minutes\n\n\nw/l_ace\nwinner/loser’s number of aces\n\n\nw/l_df\nwinner/loser’s number of doubles faults\n\n\nw/l_svpt\nwinner/loser’s number of serve points\n\n\nw/l_1stIn\nwinner/loser’s number of first serves made\n\n\nw/l_1stWon\nwinner/loser’s number of first-serve points won\n\n\nw/l_2ndWon\nwinner/loser’s number of second-serve points won\n\n\nw/l_SvGms\nwinner/loser’s number of serve games\n\n\nw/l_bpSaved\nwinner/loser’s number of break points saved\n\n\nw/l_bpFaced\nwinner/loser’s number of break points faced\n\n\nwinner/loser_rank\nwinner/loser’s WTA rank, as of the tourney_date, or the most recent ranking date before the tourney_date\n\n\n\nNote that a full glossary of the features available for match data can be found here."
  },
  {
    "objectID": "assignment/mini-project-01.html#references",
    "href": "assignment/mini-project-01.html#references",
    "title": "EDA Mini-Project Requirements and Data",
    "section": "References",
    "text": "References\nDror A (2023). nwslR: Compiles dataset for the National Women’s Soccer League (NWSL). R package version 0.0.0.9001.\nElmore R (2020). ballr: Access to Current and Historical Basketball Data. R package version 0.2.6.\nGilani S, Hutchinson G (2022). wehoop: Access Women’s Basketball Play by Play Data. R package version 1.5.0, https://CRAN.R-project.org/package=wehoop.\nHo T, Carl S (2022). nflreadr: Download ‘nflverse’ Data. R package version 1.3.1, https://CRAN.R-project.org/package=nflreadr.\nHowell B, Gilani S (2022). fastRhockey: Functions to Access Premier Hockey Federation and National Hockey League Play by Play Data. R package version 0.4.0, https://CRAN.R-project.org/package=fastRhockey.\nMorse D (2023). hockeyR: Collect and Clean Hockey Stats. R package version 1.3.1, https://github.com/danmorse314/hockeyR.\nWTA data accessed from Jeff Sackmann’s tennis GitHub repository"
  },
  {
    "objectID": "assignment/optum-project-guidelines.html",
    "href": "assignment/optum-project-guidelines.html",
    "title": "Optum Research Project Specification",
    "section": "",
    "text": "“The impact of race, social and demographic factors on health, survival, and mortality.”\nThe motivation and purpose for the 2023 Optum project is to highlight the issues and external factors that impact people’s mental and physical health, which ultimately determine the quality of one’s life. This project will example opportunities to improve disparities by identifying social, racial, demographic factors that impact and predict quality of mental and physical health.\n\n\nEach student has been allocated into a project team (of up to 4 students). Each project team has been assigned a specific project research topic using the above general theme as a prompt. Your goal is to complete the required project deliverables for your assigned project, in accordance with the guidelines detailed in the remainder of this document."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#project-theme",
    "href": "assignment/optum-project-guidelines.html#project-theme",
    "title": "Optum Research Project Specification",
    "section": "",
    "text": "“The impact of race, social and demographic factors on health, survival, and mortality.”\nThe motivation and purpose for the 2023 Optum project is to highlight the issues and external factors that impact people’s mental and physical health, which ultimately determine the quality of one’s life. This project will example opportunities to improve disparities by identifying social, racial, demographic factors that impact and predict quality of mental and physical health.\n\n\nEach student has been allocated into a project team (of up to 4 students). Each project team has been assigned a specific project research topic using the above general theme as a prompt. Your goal is to complete the required project deliverables for your assigned project, in accordance with the guidelines detailed in the remainder of this document."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#project-deliverables",
    "href": "assignment/optum-project-guidelines.html#project-deliverables",
    "title": "Optum Research Project Specification",
    "section": "Project deliverables",
    "text": "Project deliverables\nThis project has the following three key deliverables, due in the final week (starting 07/241):\n\nReproducible project report\n\nThis report is to be written as either an Rmarkdown or a quarto markdown file.\nSubmitted as rendered pdf and html output formats.\nThe report must comply with the rubric provided.\n\nProject poster\n\nRequired to be an A2 landscape size.\nSubmitted as a pdf output format, and a printed copy for the poster session.\n\nProject slide deck and presentation\n\nExecutive pdf output summary of key poster results (maximum 5 slides).\nUsed in a 5 minute presentation by the entire team on the final day.\n\n\nIt is important to know that the project poster is summarized directly from the project report, and the slide deck further summarizes the key insights from both the project report and poster. The project report thus contains all of the detailed reproducible analysis for your research question. However you are expected (and advised) to work on both the project report and poster concurrently to meet the weekly project milestones.\nAll three project deliverables must only use open data (see data guidelines), and will be publicly linked on our showcase website. The project report analysis must be made available online. It must be fully reproducible and developed only using open source software as taught in the course."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#benefits-of-the-program",
    "href": "assignment/optum-project-guidelines.html#benefits-of-the-program",
    "title": "Optum Research Project Specification",
    "section": "Benefits of the Program",
    "text": "Benefits of the Program\nThese three deliverables are designed to be openly accessible research projects. The main benefits to you in completing them successfully include (but are not limited to) the following:\n\nNetworking opportunities: you will actively present your poster and slides to Optum Executives and CMU Statistics & Data Science faculty.\nBuilding a public data science portfolio: your report, poster, and slide deck will be publicly shared as part of our program showcase.\nDeveloping marketable skills: the project involves collaborative software skills essential to industry and academia (version control, reproducibility), in addition to the statistical techniques you learn. Most importantly, you will practice communicating your work to a broad audience.\n\nProducing high quality project deliverables is an ideal way to broadcast your research for future health and data science related job-search purposes. So please put your best foot forward!"
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#research-topic-guidelines",
    "href": "assignment/optum-project-guidelines.html#research-topic-guidelines",
    "title": "Optum Research Project Specification",
    "section": "Research Topic Guidelines",
    "text": "Research Topic Guidelines\nUsing the general project theme and the required data guidelines, your project team has been assigned to one of the following 4 research topics.\n\nFinal Research Topics\n\nPremature deaths.\n\nTA Advisor: Akshay Prasadan\nDo income inequality, unemployment and high school completion rates affect the number of premature deaths of certain racial groups at the county level?\n\nPreventable hospital stays:\n\nTA Advisor: Beomjo Park\nDo income inequality, unemployment and high school completion rates affect the number of preventable hospital stays of certain racial groups at the county level?\n\nMental health:\n\nTA Advisor: YJ Choe\nDo the number of mental health professionals per county affect the number of poor mental health days?\n\nDrug overdose alcohol related deaths:\n\nTA Advisor: Alec McClean\nAre there demographic and social factors that are predictors of drug overdose, alcohol-related incidents (e.g., driving accidents)?\n\n\n\n\nExploratory and Predictive modeling\nIn preparing your three project deliverables, you should focus on both:\n\nExploratory analysis: Create visualizations to explore the underlying structure of key demographics and social determinants in the data, gaining insight about distributions and relationships between variables. These should be ideally based on reasoned hypotheses by the team.\nPredictive modeling: Are there demographic and social determinants, access to care factors that are predictors of physical and emotional health. These could be the outcome of carefully applied predictive models."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#data-guidelines",
    "href": "assignment/optum-project-guidelines.html#data-guidelines",
    "title": "Optum Research Project Specification",
    "section": "Data Guidelines",
    "text": "Data Guidelines\n\nRequired: County Health Rankings Data\nIn order to complete this project successfully, you must utilize (and appropriately cite) relevant datasets as detailed below:\n\nRequired data source: The County Health Rankings Data\nThe County Health Rankings Data as collected by the University of Wisconsin Population Health Institute, ranks every county in each state on their Health Outcomes and Health Factors. This dataset also contains the measurements used to calculate the rankings for each county.\nWe recommend reading the background information and video explainers for details.\nIn particular you must (at minimum) utilize the 2023 ranking measures which can provide more insight into the most recent health ranking outcomes priorities. This can be used to better shape your project topic and related hypotheses.\nYour analysis should mainly be done at the entire United States scale (as feasible). However you are welcome to focus on some specific counties/states to test more granular spatial hypotheses.\nAll data used must be publicly available. Any personally identifiable data, or data that is not openly accessible must be removed from your project deliverables before submission.\n\n\n\nOptional: Additional Suggestions and Data Sources\nThe following are some additional guidelines and data sources which you can consider during the course of your project analysis:\n\nThe County Health Rankings Data are typically collected over time.\n\nConsider doing a temporal or trend analysis for your analyses.\nFor predictive modeling consider adding time-varying features or forecasting an outcome, with suitable uncertainty quantification.\n\nConsider whether this County Health Rankings Data can be augmented with other publicly available datasets, over the time periods.\n\nConsider spatiotemporally merging on US Census, or COVID19 data to the County Health Rankings Data.\nSuch data is publicly accessible in R using the {tidycensus} and {covidcast} packages, for example.\nWe note that the County Health Rankings Data is a requirement, but these optional augmented datasets can help you test, and sharpen your hypotheses for some of the collected ranking metrics across US Counties."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#project-logistics",
    "href": "assignment/optum-project-guidelines.html#project-logistics",
    "title": "Optum Research Project Specification",
    "section": "Project Logistics",
    "text": "Project Logistics\n\nProject Teams and TA advisor\n\nBased on your pre-course Optum survey topic preferences, each student has been assigned to a project team of (up to) four students.\nYour project team has already been assigned to a research topic.\nYou will maintain this assigned team structure and project topic throughout the program.\nTA Advisor: Your project team will be assigned a TA advisor. Your assigned TA advisor will be your project teams’ primary point of contact throughout the program.\nAll students however are expected to do the majority of the project work together, including collecting datasets, formulating hypotheses, EDA, and predictive modeling etc.\nThe TA advisor will help project guidance and mentorship and mainly help resolve any high level technical issues during your project work.\nAll “project-lab” activities throughout the program will involve meeting with your assigned project team members and typically the TA advisor.\nIt is important for your team members to meet during the assigned times and ensure that you meet the weekly project milestones.\nStudent teams are encouraged to meet during free times during the workday, outside of lectures to continue making progress on the final project.\n\n\n\n\n\n\nProject Milestones\nThese project milestones are to be met the Friday of each week. During your Friday project lab session, the head instructor (Shamindra Shrotriya) will briefly meet with your project team and your TA advisor. During this meeting, you will provide quick progress update on that weeks’ project milestones, as detailed below:\n\nWeek 1:\n\nMeet your team and TA advisor.\nStart to understand your topic of interest and start noting formulating specific hypotheses.\nYour TA advisor will help you set up a collaboration workflow (e.g., Dropbox, Github).\nSet up the project report document as either a Rmarkdown or a quarto markdown file, and start populating it.\n\nWeek 2:\n\nFormulate initial key hypotheses with TA advisor.\nSource initial datasets and read them into R.\nDo some basic exploratory data analysis (EDA), i.e., produce some summary plots and update your project report. This may change, but keep adding in findings.\nTA Advisor to set up an overleaf project poster file for the team. Must be A2 landscape format. Your team can use other formats per your preference.\nStart also populating some poster sections like the introduction, data sources, and placeholder for the conclusion. Mirror these from your project report.\nYour project report and poster should be done concurrently to save time!\n\nWeek 3:\n\nMore hypotheses should be tested and introduction, data sources section should be finalized in both the project report and project poster.\nAdditional exploratory plot with commentary should be finalized in both the project report and project poster.\nCarefully list assumptions, not just insights when summarizing any findings.\nStart preparing predictive modeling questions of interest and source some datasets in R to help answer the questions.\n\nWeek 4:\n\nAdditional exploratory plots with commentary should be finalized in both the project report and project poster.\nPredictive models should be run. Check which predictors provide most explanatory power for the outcome. Note down key assumptions and data limitations as you draft your report and poster findings.\n\nWeek 5:\n\nRefine your predictive models. Draft predictive questions section in the poster, including question, data, and methodology used. Explain your model and variable selection procedures used.\nReport should be drafted at this stage, similar to the poster.\n\nWeek 6:\n\nPolish the report and poster. Ensure that you can generate pdf and html files for the report submission.\nCreate a basic slide deck and summarize main results. This should be a quarto markdown reveal.js document, as taught in the course lectures.\nYou will have only 5 minutes for your presentation, so it should be a maximum of 5 slides.\n\nWeek 7:\n\nOptum HQ visit 07/17 to 07/20 (inclusive).\nNot much work to do this week.\nJust keep polishing the report and poster session in the background on the Friday project-lab.\n\nWeek 8:\n\nSubmit your project poster pdf by 07/27 to allow for printing.\nSubmit your project report pdf and html files by 07/27.\nSubmit your project slide deck pdf by 07/27."
  },
  {
    "objectID": "assignment/optum-project-guidelines.html#footnotes",
    "href": "assignment/optum-project-guidelines.html#footnotes",
    "title": "Optum Research Project Specification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDetails on deliverable due dates will be announced after semester starts. Stay tuned!↩︎"
  },
  {
    "objectID": "assignment/report-writing-guideline.html",
    "href": "assignment/report-writing-guideline.html",
    "title": "SURE 2023: Report Writing Guideline",
    "section": "",
    "text": "This guideline1 is intended to include elements necessary for a successful report applying statistical methods to answer research questions using real data. It cannot, however, list every element required to make a well-written, convincing, and comprehensive report."
  },
  {
    "objectID": "assignment/report-writing-guideline.html#footnotes",
    "href": "assignment/report-writing-guideline.html#footnotes",
    "title": "SURE 2023: Report Writing Guideline",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe thank Prof. Alex Reinhart for sharing these guidelines with us. They were originally developed by the teaching staff for the Undergraduate Advanced Data Analysis course (36-402), as taught at CMU.↩︎"
  },
  {
    "objectID": "class/01-class.html",
    "href": "class/01-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/01-class.html#slides",
    "href": "class/01-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/02-class.html",
    "href": "class/02-class.html",
    "title": "Exploring data: Into the tidyverse",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/02-class.html#slides",
    "href": "class/02-class.html#slides",
    "title": "Exploring data: Into the tidyverse",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/03-class.html",
    "href": "class/03-class.html",
    "title": "The grammar of graphics and ggplot2",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides\n\n\nThese were additional supplementary slides which Shamindra went through to describe the %&gt;% operator and function composition."
  },
  {
    "objectID": "class/03-class.html#slides",
    "href": "class/03-class.html#slides",
    "title": "The grammar of graphics and ggplot2",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides\n\n\nThese were additional supplementary slides which Shamindra went through to describe the %&gt;% operator and function composition."
  },
  {
    "objectID": "class/04-class.html",
    "href": "class/04-class.html",
    "title": "Visualizing 1D categorical and continuous variables",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/04-class.html#slides",
    "href": "class/04-class.html#slides",
    "title": "Visualizing 1D categorical and continuous variables",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/05-class.html",
    "href": "class/05-class.html",
    "title": "Visualizing 2D categorical and continuous by categorical",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/05-class.html#slides",
    "href": "class/05-class.html#slides",
    "title": "Visualizing 2D categorical and continuous by categorical",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/06-class.html",
    "href": "class/06-class.html",
    "title": "Density Estimation",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/06-class.html#slides",
    "href": "class/06-class.html#slides",
    "title": "Density Estimation",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/07-class.html",
    "href": "class/07-class.html",
    "title": "Clustering: K-means",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/07-class.html#slides",
    "href": "class/07-class.html#slides",
    "title": "Clustering: K-means",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/08-class.html",
    "href": "class/08-class.html",
    "title": "Heirarchical Clustering",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/08-class.html#slides",
    "href": "class/08-class.html#slides",
    "title": "Heirarchical Clustering",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/10-class.html",
    "href": "class/10-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/10-class.html#slides",
    "href": "class/10-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/11-class.html",
    "href": "class/11-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/11-class.html#slides",
    "href": "class/11-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/12-class.html",
    "href": "class/12-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/12-class.html#slides",
    "href": "class/12-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/13-class.html",
    "href": "class/13-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/13-class.html#slides",
    "href": "class/13-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/14-class.html",
    "href": "class/14-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/14-class.html#slides",
    "href": "class/14-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/15-class.html",
    "href": "class/15-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/15-class.html#slides",
    "href": "class/15-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/16-class.html",
    "href": "class/16-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/16-class.html#slides",
    "href": "class/16-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/17-class.html",
    "href": "class/17-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/17-class.html#slides",
    "href": "class/17-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/18-class.html",
    "href": "class/18-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/18-class.html#slides",
    "href": "class/18-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/19-class.html",
    "href": "class/19-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/19-class.html#slides",
    "href": "class/19-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/20-class.html",
    "href": "class/20-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/20-class.html#slides",
    "href": "class/20-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/21-class.html",
    "href": "class/21-class.html",
    "title": "Introduction and Welcome to SURE 2123",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/21-class.html#slides",
    "href": "class/21-class.html#slides",
    "title": "Introduction and Welcome to SURE 2123",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/22-class.html",
    "href": "class/22-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/22-class.html#slides",
    "href": "class/22-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/23-class.html",
    "href": "class/23-class.html",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/23-class.html#slides",
    "href": "class/23-class.html#slides",
    "title": "Introduction and Welcome to SURE 2023",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "class/index.html",
    "href": "class/index.html",
    "title": "Lectures and Readings",
    "section": "",
    "text": "Each lecture in the left sidebar contains the relevant pdf slides, and some additional useful resources for you to deeply explore a lecture topic. We will continually update any additional resources (e.g., youtube links, articles, blog post tutorials etc.) for a given lecture as needed. So please keep checking back in regularly throughout the program.\n\n\n\n\n\n\nGive us tips!\n\n\n\nYou are also welcome to suggest new resources (links) for us to include for a given topic page. We’re always keen to grow the body of knowledge contained in the lectures throughout the program.\n\n\nYou can view all lecture materials by navigating the links in the left sidebar, or via the schedule."
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "Students participating in our Summer Undergraduate Research Experience (SURE) here at Carnegie Mellon are to consider themselves part of the Carnegie Mellon academic community and are expected to meet and maintain the highest personal and professional ethics and conduct.\nWe are committed to cultivating a transformative and educational experience, as well as safeguarding personal health and well-being. We require students to act with personal and intellectual integrity, to speak honestly, and to treat themselves and others with the utmost respect.\nStudents participating in the program are expected to:\n\nRespect the rights of your instructors, assistants and other staff, as well as your peers\nPromote the health and safety of all members of our diverse community\nTreat others with honesty and fairness\nParticipate in the program with the highest level of professionalism and motivation to learn\nRespect the property of others as well as that of Carnegie Mellon\nUnderstand and abide by all Carnegie Mellon community standards as well as all local, state, and federal laws\nAttend, be on time for, and actively participate in all program sessions.\n\nAll participating students are expected to have timely attendance and to participate in all mandatory program sessions, including all in-person, virtual, and group activities. All students are expected to be present, prepared, and ready to actively engage in each session. Student engagement is central to the program and pivotal to the overall success of the summer experience.\n\nIf you believe you will need to be absent for an upcoming session for any reason (illness, personal reasons, etc.), you will need to contact your Summer Program Director and Program Advisor as proactively as possible to communicate any potential absences.\nPlease note: extended and/or unexcused absences may incur potential consequences, up to and including dismissal from the program and the termination of your stipend\n\nThe Statistics & Data Science department and Carnegie Mellon prohibits conduct that creates a hostile environment for faculty, staff, students, or other parties. Examples include:\n\nDisrespect toward an instructor, peer, or other members of the Statistics & Data Science community\nAbusive, intimidating, hostile or obscene language, gestures, or behavior\nAny kind of discrimination or harassment that would create a hostile or abusive environment for any member of our community\nAny kind of unwelcome coercive, exploitive, or other forms of prohibited sexual misconduct\n\nAny form of sexual misconduct will not be tolerated by the program. All participating students are expected to read and become familiar with Carnegie Mellon’s sexual misconduct policies and will be expected to abide by these policies starting the day they arrive. All students are subject to CMU’s Title IX office policies and procedures as well as any related potential disciplinary action.\nIf students need any kind of support or assistance during their time here, please contact one of the following SURE 2023 staff:\n\nGlenn Clune: SURE Academic Advisor Email: gclune@andrew.cmu.edu Office Location: Baker Hall 132L In office: Monday & Tuesday\nTeraya White: SURE Academic Advisor Email: terayaw@andrew.cmu.edu\nJamie McGovern: SURE Program Director Email: jamiemcg@andrew.cmu.edu\n\nWhen all members of the community uphold these values, we are able to provide a formative and collaborative experience for all summer program participants."
  },
  {
    "objectID": "credits.html",
    "href": "credits.html",
    "title": "Website Credits",
    "section": "",
    "text": "This SURE 2023 website is built by leveraging tools and materials generously made available by members of the open source software community. We would like to list some1 of the key resources we utilized to create this website:"
  },
  {
    "objectID": "credits.html#footnotes",
    "href": "credits.html#footnotes",
    "title": "Website Credits",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTrying to list every possible resource is a sisyphean task, which we won’t attempt to do here.↩︎"
  },
  {
    "objectID": "data_eng/01-class-data-eng.html",
    "href": "data_eng/01-class-data-eng.html",
    "title": "Data Engineering: Getting acquainted with the UNIX philosophy",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "data_eng/01-class-data-eng.html#slides",
    "href": "data_eng/01-class-data-eng.html#slides",
    "title": "Data Engineering: Getting acquainted with the UNIX philosophy",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "data_eng/02-class-data-eng.html",
    "href": "data_eng/02-class-data-eng.html",
    "title": "Data Engineering: Getting comfortable with the UNIX philosophy",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "data_eng/02-class-data-eng.html#slides",
    "href": "data_eng/02-class-data-eng.html#slides",
    "title": "Data Engineering: Getting comfortable with the UNIX philosophy",
    "section": "",
    "text": "The slides for today’s lesson are available online as an PDF file. Use the button below to open the slides either in a new tab in your browser. Or you can just scroll the embedded slides below. For the embedded slides below, you can also click in the slides and navigate through them with your left and right arrow keys, for convenience.\n Download PDF of all slides"
  },
  {
    "objectID": "guides/computing-setup.html",
    "href": "guides/computing-setup.html",
    "title": "Computing Setup",
    "section": "",
    "text": "A friendly note from your friendly TA advisor Quang\n\n\n\nWelcome to the Summer Undergraduate Research Experience (SURE) 2023 hosted by the Department of Statistics & Data Science at Carnegie Mellon University. We are excited to guide you through exciting topics in statistics and data science, focusing on applications in sports and health analytics.\nTo get you started, please complete our step-by-step instructions for setting up the common tools that you will use throughout the program.\n–Quang"
  },
  {
    "objectID": "guides/computing-setup.html#step-1-install-r",
    "href": "guides/computing-setup.html#step-1-install-r",
    "title": "Computing Setup",
    "section": "Step 1: Install R",
    "text": "Step 1: Install R\n\n\n\n\n\n\nInstall R\n\n\n\n\n\n(Note that the following instructions apply to the latest R version (4.3.0) as of May 31, 2023)\nClick on DOWNLOAD AND INSTALL R. This will direct you to the CRAN (Comprehensive R Archive Network) website.\nmacOS\n\nClick on Download R for macOS.\nChoose the .pkg file suitable for your Mac (Apple silicon (M1/M2) Macs or older Intel Macs.)\nOpen the .pkg file after the download is complete.\nFollow the installation instructions.\n\nWindows\n\nClick on Download R for Windows.\nClick on install R for the first time (on the same line as the base subdirectory.)\nChoose Download R 4.3.0 for Windows.\nOpen the .exe file after the download is complete.\nFollow the installation instructions."
  },
  {
    "objectID": "guides/computing-setup.html#step-2-install-rstudio",
    "href": "guides/computing-setup.html#step-2-install-rstudio",
    "title": "Computing Setup",
    "section": "Step 2: Install RStudio",
    "text": "Step 2: Install RStudio\n\n\n\n\n\n\nImportant\n\n\n\nR must be installed before RStudio.\n\n\n\n\n\n\n\n\nInstall RStudio\n\n\n\n\n\nClick on DOWNLOAD RSTUDIO DESKTOP… Your operating system is automatically detected. (If your OS is not correctly detected, scroll down and choose the right version for your system.)\nmacOS\n\nOpen the .dmg file after the download is complete.\nDrag and drop it to your Applications folder.\n\nWindows\n\nOpen the .exe file after the download is complete.\nFollow the installation instructions.\n\nOpen RStudio once the installation is finished. You should get something similar to the image below. We will run a few commands later in the Console pane, which is located on the bottom left corner and highlighted in red."
  },
  {
    "objectID": "guides/computing-setup.html#step3",
    "href": "guides/computing-setup.html#step3",
    "title": "Computing Setup",
    "section": "Step 3: Check R and RStudio installations",
    "text": "Step 3: Check R and RStudio installations\nNext, we run a quick check to verify that everything looks right after installations,\n\n\n\n\n\n\nPost-installation check\n\n\n\n\n\nOpen RStudio and type in the following command in the Console pane on the bottom left.\n\nversion\n\nThis will print out the current version of R on your machine. The output should look similar to what shown below (the first 4 lines might be different, depending on your operating system.)\n\n\n               _                           \nplatform       x86_64-apple-darwin20       \narch           x86_64                      \nos             darwin20                    \nsystem         x86_64, darwin20            \nstatus                                     \nmajor          4                           \nminor          3.0                         \nyear           2023                        \nmonth          04                          \nday            21                          \nsvn rev        84292                       \nlanguage       R                           \nversion.string R version 4.3.0 (2023-04-21)\nnickname       Already Tomorrow            \n\n\nThe following gif shows what it looks like in action."
  },
  {
    "objectID": "guides/computing-setup.html#step-4-install-required-packages",
    "href": "guides/computing-setup.html#step-4-install-required-packages",
    "title": "Computing Setup",
    "section": "Step 4: Install required packages",
    "text": "Step 4: Install required packages\nWe suggest that you install the following minimal set of R packages which are needed to get started with SURE 2023. We will recommend more packages for you to install as we progress through the program.\n\n\n\n\n\n\nPackage installation\n\n\n\n\n\nIn R, a package is a collection of functions, data and compiled code. In addition to a set of built-in base packages, there are numerous external R packages written by the community to add specific functionality.\nTo get started with SURE 2023, you will need to install a minimal set of packages. Again, open RStudio and type in the following command in the Console pane on the bottom left (refer to the gif in Step 3 for how to access the RStudio Console pane).\n\nrec_packages &lt;- c(\"tidyverse\", \"styler\", \"xaringan\", \"xaringanthemer\", \n                  \"xaringanExtra\", \"tidymodels\")\ninstall.packages(rec_packages)\n\nWe can verify successful package installation, e.g., for the tidyverse, which is arguably the most popular R package for data science. To do this, run the following command in the RStudio Console pane.\n\nlibrary(tidyverse)\n\nYou should get a message similar to the output below.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "guides/computing-setup.html#step-5-setup-and-run-r-primers-on-posit-cloud",
    "href": "guides/computing-setup.html#step-5-setup-and-run-r-primers-on-posit-cloud",
    "title": "Computing Setup",
    "section": "Step 5: Setup and run R Primers on Posit Cloud",
    "text": "Step 5: Setup and run R Primers on Posit Cloud\nIn addition to following the steps above for installing R and RStudio on your computer, we recommend you make a free Posit Cloud account at https://posit.cloud/. This is a free, browser-based version of R and RStudio that also provides access to a growing number of R tutorials / primersrelevant to the summer program material\n\n\n\n\n\n\nSetup Posit Cloud\n\n\n\n\n\nAfter you create a free Posit Cloud account, click on the navigation menu by “Your Workspace”. Then click on “Primers” to bring up a menu of tutorials. Prior to June 6th, please complete the following (listed in order of importance):\n\nin “The Basics”, you only need to complete the “Programming Basics” primer,\ncomplete all three primers in “Work with Data”,\ncomplete all seven primers in “Write Functions”.\n\nFeel free to explore the other primers listed, specifically for “Iterate” and “Tidy Your Data”. We will be covering data visualization extensively in the first two weeks, so you do not worry about working through the data visualization primers.\nAfter completing the above primers available on the RStudio Cloud, try replicating the some type of R programming basics in your own local version of R and RStudio installed on your computer. RStudio Cloud is a great practical alternative to use in case we are unable to resolve errors with regards to installation on your own personal computer (an unlikely scenario). We strongly encourage you to use an installed version of R and RStudio throughout the program, due to RStudio Cloud data limitations that are important for your research projects throughout the summer.\n\n\n\nDo not worry if you are unable to complete all of the R tutorials and steps above prior to June 5th. The teaching assistants will be reviewing the R and tidyverse basics and materials in the first week’s lab sessions. Again, if you have any questions, do not hesitate to reach out to the instructors above and we look forward to meeting you June 5th!"
  },
  {
    "objectID": "guides/computing-setup.html#books",
    "href": "guides/computing-setup.html#books",
    "title": "Computing Setup",
    "section": "Books",
    "text": "Books\n\n\n\n\n\n\nR for Data Science\n\n\n\n\n\n\n\n\n\n\nA great introduction to doing data science in R. It provides a thorough overview of basic data science tasks, most notably data tidying, wrangling, and visualization with the tidyverse.\n\n\n\n\n\n\n\n\n\nModern Data Science with R\n\n\n\n\n\n\n\n\n\n\nAnother good introductory book for data science. It contains a wide array of topics, including a chapter on data science ethics and special topics on geospatial data.\n\n\n\n\n\n\n\n\n\nAn Introduction to Statistical Learning\n\n\n\n\n\n\n\n\n\n\nA simple introduction to statistical machine learning without much technical detail. It covers modeling concepts that we will be discussing in this program such as classification, regression, variable selection, clustering, and tree-based methods."
  },
  {
    "objectID": "guides/computing-setup.html#websites",
    "href": "guides/computing-setup.html#websites",
    "title": "Computing Setup",
    "section": "Websites",
    "text": "Websites\n\n\n\n\n\n\nggplot2 references\n\n\n\n\n\n\n\n\n\n\nFeaturing ggplot2 cheatsheet, function documentations, FAQs, and extensions."
  },
  {
    "objectID": "guides/computing-setup.html#videos",
    "href": "guides/computing-setup.html#videos",
    "title": "Computing Setup",
    "section": "Videos",
    "text": "Videos\n\n\n\n\n\n\nDavid Robinson’s TidyTuesday screencasts\n\n\n\n\n\n\n\n\n\n\nEach video is a detailed walk-through on how to approach, clean, summarize, visualize, and analyze a dataset provided by the TidyTuesday project. Useful R tips and tricks are often offered. For context, TidyTuesday releases a weekly dataset, aiming to promote data analysis with the tidyverse suite of packages. Numerous examples of TidyTuesday contributions (e.g., visualizations) can be found under the #TidyTuesday Twitter hashtag."
  },
  {
    "objectID": "guides/computing-setup.html#rstudio-customization",
    "href": "guides/computing-setup.html#rstudio-customization",
    "title": "Computing Setup",
    "section": "RStudio Customization",
    "text": "RStudio Customization\n\n\n\n\n\n\nCode formatting\n\n\n\n\n\n\n\n\n\n\nThe tidyverse style guide is a great reference for good coding style. It is supported by the styler package in R. The figure above provides a simple demonstration for code formatting with styler, taken from the package site.\n\n\n\n\n\n\n\n\n\nRStudio theme\n\n\n\n\n\nRStudio can be customized with different themes. To explore built-in themes,\n\nNavigate to the menu bar at the top of your screen\nChoose Tools \\(\\rightarrow\\) Global Options \\(\\rightarrow\\) Appearance\nChange your RStudio theme under Editor theme\n\nNote that within the Appearance tab, there are also options for changing your Editor font, Editor font size, etc.\nThe following gif illustrates a theme switch from Textmate (default) to Tomorrow Night Bright, which is the theme used by your TA advisor Quang.\n\n\n\nFurther, the rsthemes package provides additional options to the original built-in themes. The package can be installed with the following command:\n\ninstall.packages(\n  \"rsthemes\",\n  repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption(\"repos\"))\n)\n\nYou can then follow the same instructions as above and select your favorite theme. For your information, your co-instructor Shamindra uses the Dracula theme.\n\n\n\n\n\n\n\n\n\nFont ligatures\n\n\n\n\n\n(This section is heavily borrowed from Jeffrey Girard’s excellent blog post on Using Fira Code Ligatures in RStudio. Please check out the linked article for step-by-step instructions.)\nTo quote the blog post (which quoted the Fira Code README):\n\n\nProblem\n\n\nProgrammers use a lot of symbols, often encoded with several characters. For the human brain, sequences like -&gt;, &lt;= or := are single logical tokens, even if they take two or three characters on the screen. Your eye spends a non-zero amount of energy to scan, parse and join multiple characters into a single logical one. Ideally, all programming languages should be designed with full-fledged Unicode symbols for operators, but that’s not the case yet.\n\n\nSolution\n\n\nFira Code is a free monospaced font containing ligatures for common programming multi-character combinations. This is just a font rendering feature: underlying code remains ASCII-compatible. This helps to read and understand code faster. For some frequent sequences like .. or //, ligatures allow us to correct spacing.\n\n\nHere are some examples of ligatures for common operators in R.\n\n\n\n\n\n\n\nWithout ligature\nWith ligature\n\n\n\n\nx &lt;- 10\n\n\n\nx &lt;= y\n\n\n\nx &gt;= y\n\n\n\nx == y\n\n\n\nx != y\n\n\n\n\nOnce again, please see the aforementioned blog post for a detailed instruction of how to set up ligatures in RStudio."
  },
  {
    "objectID": "guides/computing-setup.html#initial-cmu-secure-wifi-setup",
    "href": "guides/computing-setup.html#initial-cmu-secure-wifi-setup",
    "title": "Computing Setup",
    "section": "Initial CMU SECURE WiFi setup",
    "text": "Initial CMU SECURE WiFi setup\n \\(\\text{}\\) When you arrive at your CMU housing, or on the CMU campus you will receive a printed (paper) card which contains your personal CMU WiFi username and password (for SURE 2023). You must keep your assigned card secure and private. To login to CMU WiFi, do the following (inside your CMU housing, or on CMU campus):\n\n\n\n\n\n\nInstruction: Setting up CMU campus and Housing WiFi\n\n\n\n\nGrab your paper card containing your original guest WiFi username and password.\nGo to identity.andrew.cmu.edu.\nEnter the guest ID and initial password.\nClick Login.\nFollow the on-screen steps to set a secure password for the guest account.\nImportant: Please change your assigned temporary password immediately after you login, otherwise your account will expire in 2 days. We will have to keep asking for new logins for you since it costs you valuable time away from WiFi ."
  },
  {
    "objectID": "guides/computing-setup.html#resetting-cmu-secure-expired-wifi-password",
    "href": "guides/computing-setup.html#resetting-cmu-secure-expired-wifi-password",
    "title": "Computing Setup",
    "section": "Resetting CMU SECURE expired WiFi password",
    "text": "Resetting CMU SECURE expired WiFi password\nIn case you do set up the above, but forget to change your password in time and it expires, please follow the instructions below to reset it:\n\n\n\n\n\n\nInstruction: Resetting expired guest WiFi password\n\n\n\n\n\n\nGrab your paper card containing your original guest WiFi username and (expired) password.\nGo to http://identity.andrew.cmu.edu/\nEnter your username and original (expired) password.\nAt the next prompt re-enter your username and (expired) password.\nThen enter your current (expired) password and new password twice to confirm it.\nMake sure to note down your new password in a secure place.\nYou should now be reconnected to CMU-SECURE  using your original guest username and new password (as you had created in the previous step)"
  },
  {
    "objectID": "guides/pittsburgh-fun-activities.html",
    "href": "guides/pittsburgh-fun-activities.html",
    "title": "Fun activities to do in Pittsburgh",
    "section": "",
    "text": "A friendly note from your friendly co-instructor Meg\n\n\n\nPittsburgh gets a bad rap, but I’ve found it to be a really fun, active, vibrant city! To that end, as an instructor I want you to get the most out of this program, both academically and personally, so I’ve compiled a list of fun activities that you could try if you find yourself bored in the evenings or on the weekends. Note that it may be a bit biased. I haven’t tried/visited each of these things, but the ones I haven’t done myself still come highly recommended from friends in town. I hope you can get out there and do some cool stuff!\n–Meg\n\n\n\nIf you’re into sports\nPittsburgh sports are awesome (regardless of how well the teams may or may not be doing in their respective seasons…). It’s a big deal here. Also, fun fact, the city requires all professional teams to have Black & Gold as their colors.\n\nPittsburgh Pirates (MLB)\n\nArguably one of the most beautiful stadium views in baseball (looks out over downtown PGH)\nTickets usually quite accessible, compared to other MLB teams, can be found here\n\nPittsburgh Riverhounds SC (USL Championship)\n\nFirst-tier experience for second-tier prices, find tickets here\n\nPittsburgh Steelers (NFL, out of season)\nPittsburgh Penguins (NHL, out of season)\n\n\n\nIf you love nature\n\nPhipps Conservatory\n\nBeautiful botanical gardens just a stone’s throw away from campus\nLots of cool events, see the website for details\n\nFrick Park\n\nFantastic walking/running trails, great hammock spots\nHonestly feels like you’ve escaped to the wilderness but you’re still in Pittsburgh\n\nSchenley Park\n\nEven closer to campus than Frick, somewhat smaller but equally beautiful\nThe sunset over Flagstaff Hill is just *chef’s kiss*\n\nThree Rivers Heritage Trail\n\nPaved trail for walking/running/biking\nCan be accessed from various points around the city, I usually go to the Southside Riverfront Park for long runs\n\n\n\n\nIf you like culture\n\nCarnegie Library\n\nA whole network of libraries across the city, but it’s main location is at the Museum on Forbes (see below)\nLots of events available, and just a cool spot\n\nCarnegie Museum\n\nActually four museums, including the Museum of Art, Museum of Natural History, Science Center, and the Andy Warhol Museum\nI can personally vouch for the Science Center being really fun, but I’ve heard the others are quite cool as well, and a few of them are walking distance from campus\n\nVarious festivals\n\nYou can find a list of annual events here– Picklesburgh is a personal favorite!\nThere are also plenty of nice farmers markets to check out\n\n\n\n\nGenerally cool areas to explore\n\nStrip District\n\nSpecialty grocery stores (Korean, Mexican, Italian, etc.)\nRestaurants, coffee shops, various other food-related activities\n\nDowntown (Dahntahn)\n\nPoint State Park sits at the confluence of the Allegheny and Monongahela\nThe Duquesne Incline is a classic Pittsburgh tourist activity\n\nLawrenceville (Butler St.), Shadyside (Walnut St.), Squirrel Hill (Murray Ave)\n\nNeighborhoods with some nice shopping/restaurant areas\n\nSome restaurants that I recommend (again, biased, not exhaustive)\n\nKiin Lao (prev. Bangkok Balcony, Squirrel Hill)\nUdipi (Monroeville, very far but so delicious, no online presence whatsoever)\nStack’d (Oakland, custom burgers, very close to campus)\nIron Born Pizza (Detroit-style, which I did not know existed, good delivery option)"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html",
    "href": "guides/pittsburgh-student-resources.html",
    "title": "Pittsburgh-based resources",
    "section": "",
    "text": "A friendly note from your friendly Academic Advisor Glenn\n\n\n\nWelcome to Pittsburgh! This fantastic city will be your home for the next two months, and we want to make sure you have access to any support systems you may need during that time. We hope that you’ll be able to get everything possible out of the SURE program, so these resources should help alleviate any stress that could arise elsewhere. We’ve collated the following list of Pittsburgh-based resources to assist you, should you have need during the program.\n–Glenn"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html#sponsored-cmu-id",
    "href": "guides/pittsburgh-student-resources.html#sponsored-cmu-id",
    "title": "Pittsburgh-based resources",
    "section": "Sponsored CMU ID",
    "text": "Sponsored CMU ID\nA CMU sponsored ID is an optional, additional expense for students that can provide the following:\n\nGeneral building access\nFitness Center Access (classes not included)\nLibrary access & borrowing of books\nCMU campus shuttles & escort services\n\nPlease note that Pittsburgh Bus Transit is not included"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html#pittsburgh-bustransit-pass",
    "href": "guides/pittsburgh-student-resources.html#pittsburgh-bustransit-pass",
    "title": "Pittsburgh-based resources",
    "section": "Pittsburgh Bus/Transit Pass",
    "text": "Pittsburgh Bus/Transit Pass\nIf you would like to utilize public transit to get from your program housing to campus, or to explore what Pittsburgh has to offer, please see the below links for more information:\n\nCurrent Bus Fares\nGetting a bus/fare pass\nPersonally, I recommend both Google Maps (for optimal mapping and outlining of routes) and the Transit app (for real-time tracking of busses) to coordinate bus plans"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html#medicalwellness-resources",
    "href": "guides/pittsburgh-student-resources.html#medicalwellness-resources",
    "title": "Pittsburgh-based resources",
    "section": "Medical/Wellness Resources",
    "text": "Medical/Wellness Resources\nIf you find yourself in need of physical, mental, or emotional attention, please utilize these local institutions for assistance:\n\nUPMC Urgent Care Shadyside\n\n5231 Centre Ave, Pittsburgh, PA 15232\n412-623-4114\n\nUPMC Presbyterian Hospital\n\n200 Lothrop St, Pittsburgh, PA 15213\n412-755-2307\n\nAllegheny Health Network Emergency Care Brentwood\n\n3290 Saw Mill Run Blvd, Brentwood, PA 15227\n\nResolve Crisis Services\n\n333 North Braddock Ave, Pittsburgh, PA 15213\n1-888-796-8226\n\nAllies for Health and Well-Being\n\nMedical support and community-based resources for individuals living with or at risk for HIV, viral hepatitis, and other sexually transmitted infections\nLocal support and resources for members of the LGBTQ community"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html#food-insecurity",
    "href": "guides/pittsburgh-student-resources.html#food-insecurity",
    "title": "Pittsburgh-based resources",
    "section": "Food Insecurity",
    "text": "Food Insecurity\nIf you find yourself struggling with having enough food to get through your time here, please contact the following resource for assistance:\n\nGreater Pittsburgh Community Food Bank 412-460-3663 ext. 655"
  },
  {
    "objectID": "guides/pittsburgh-student-resources.html#finding-a-faith-community",
    "href": "guides/pittsburgh-student-resources.html#finding-a-faith-community",
    "title": "Pittsburgh-based resources",
    "section": "Finding a Faith Community",
    "text": "Finding a Faith Community\nIf you are part of a religious community and want to find a local community during your\ntime here, please use the following resource to find a faith community:\n\nCMU Council of Religious Advisors"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            SURE 2023\n        ",
    "section": "",
    "text": "SURE 2023\n        \n        \n            Explore cutting-edge statistics and data science methodology with applications in healthcare (Optum) and sports (CMSAC) analytics\n        \n        \n            Summer 2023Department of Statistics & Data ScienceCarnegie Mellon University\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\nCourse details\n\n   Meg Ellingwood and Shamindra Shrotriya\n   Monday - Friday\n   9:30 – 4:00 PM\n   POS151 and PHA18A\n   June 5 – July 28, 2023"
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "SURE 2023",
    "section": "",
    "text": "Home\n    People"
  },
  {
    "objectID": "people.html#instructors",
    "href": "people.html#instructors",
    "title": "SURE 2023",
    "section": "Instructors",
    "text": "Instructors\n\n\n\n\n\n\n\n\n\n\nMeg Ellingwood\n\n\nSURE 2023 Faculty (CMSAC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShamindra Shrotriya\n\n\nSURE 2023 Faculty (Optum)\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html#ta-advisors",
    "href": "people.html#ta-advisors",
    "title": "SURE 2023",
    "section": "TA Advisors",
    "text": "TA Advisors\n\n\n\n\n\n\n\n\n\n\nYuchen Chen\n\n\nTA Advisor (CMSAC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nYJ Choe\n\n\nTA Advisor (Optum)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNick Kissel\n\n\nTA Advisor (CMSAC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlec McClean\n\n\nTA Advisor (Optum)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuang Nguyen\n\n\nTA Advisor (CMSAC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeomjo Park\n\n\nTA Advisor (Optum)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAkshay Prasadan\n\n\nTA Advisor (CMSAC)\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html#student-support",
    "href": "people.html#student-support",
    "title": "SURE 2023",
    "section": "Student Support",
    "text": "Student Support\n\n\n\n\n\n\n\n\n\n\nLeeAnn Chapman\n\n\nSURE 2023 Accounting Assistant\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlenn Clune\n\n\nSURE 2023 Academic Advisor, Academic Program Manager\n\n\n\n\n\n\n\n\n\n\n\n\n\nJessica Paschke\n\n\nSURE 2023 Program Administrator\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeraya White\n\n\nSURE 2023 Academic Advisor\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html#executive-team",
    "href": "people.html#executive-team",
    "title": "SURE 2023",
    "section": "Executive team",
    "text": "Executive team\n\n\n\n\n\n\n\n\n\n\nJamie McGovern\n\n\nSpecial Faculty, Director of the Master’s in Statistical Practice Program (CMU)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRebecca Nugent\n\n\nStephen E. and Joyce Fienberg Professor of Statistics & Data Science (CMU)\n\n\n\n\n\n\n\n\n\n\n\n\n\nRon Yurko\n\n\nAssistant Teaching Professor of Statistics & Data Science (CMU)\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people/executive/mcgovern-jamie.html",
    "href": "people/executive/mcgovern-jamie.html",
    "title": "Jamie McGovern",
    "section": "",
    "text": "Home\n    People\n    Executive team\n    Jamie McGovern"
  },
  {
    "objectID": "people/executive/mcgovern-jamie.html#biography",
    "href": "people/executive/mcgovern-jamie.html#biography",
    "title": "Jamie McGovern",
    "section": "Biography",
    "text": "Biography\nJamie McGovern joined the Carnegie Mellon Department of Statistic & Data Science after a long career in management consulting. As Special Faculty and the Director of the Master of Statistical Practice (MSP) Program, Jamie is responsible for developing the professional skills of MSP students working to build competencies valued in industry and academia. With extensive consulting experience building and leading teams responsible for the development and delivery of global transformation engagements, Jamie works with industry partners to develop instructional MSP capstones that are central to the experiential educational philosophy of developing and practicing concepts while focusing on the context of real-world, practical application.\nAfter an extensive work history in Human Capital Management selling, solutioning, and delivering engagements related to business process re-engineering, strategic organizational design, and enablement of on-premise and cloud enterprise technologies, he most recently co-founded a data science consulting services organization with a mission statement of mentoring and upskilling underserved populations, using education and a public health intervention, and building employee competencies through deployment on analytic consulting projects.\nJamie has held a number of senior consulting industry roles. His experience over the prior 20+ years spans Life Sciences, Financial Services, Consumer Products, Energy, Telecommunications, and Media & Entertainment industries. In the area of Human Capital Management transformation and HR Operations, Jamie has led diverse, cross-border teams in the design and delivery functional and technical solutions geared towards improving the competitiveness of organizations in the global economy while building highly functional and capable practices and cross-border teams of consulting professionals.\nJamie’s areas of thought leadership include strategic talent development, employee data analytics design, Human Capital leading practices, knowledge sharing, and collaboration. He has been an invited speaker at industry conferences and academic events."
  },
  {
    "objectID": "people/executive/nugent-rebecca.html",
    "href": "people/executive/nugent-rebecca.html",
    "title": "Rebecca Nugent",
    "section": "",
    "text": "Home\n    People\n    Executive team\n    Rebecca Nugent"
  },
  {
    "objectID": "people/executive/nugent-rebecca.html#biography",
    "href": "people/executive/nugent-rebecca.html#biography",
    "title": "Rebecca Nugent",
    "section": "Biography",
    "text": "Biography\nRebecca Nugent is the Stephen E. and Joyce Fienberg Professor of Statistics & Data Science and Head of the Carnegie Mellon Department of Statistics & Data Science. She received her PhD in Statistics from the University of Washington, her M.S. in Statistics from Stanford University, and her B.A. in Mathematics, Statistics, and Spanish from Rice University.\nDr. Nugent has expertise in designing and implementing data science/AI professional development programs for business leaders in industries including health care, finance, automotive/manufacturing, and life sciences. She was the faculty co-Director of the Moderna AI Academy and the Founding Director of the Statistics & Data Science Corporate Capstone program, an experiential learning initiative that matches groups of faculty and students with data science problems in industry, non-profits, and government organizations.\nShe has won several national and university teaching awards including the American Statistical Association Waller Award for Innovation in Statistics Education and serves as one of the co-editors of the Springer Texts in Statistics. She recently served as the co-chair for the National Academy of Sciences study on Improving Defense Acquisition Workforce Capability in Data Use and served on the NAS study on Envisioning the Data Science Discipline: The Undergraduate Perspective. Dr. Nugent has worked extensively in clustering and classification methodology with an emphasis on high-dimensional, big data problems and record linkage applications. Her current research focus is the development and deployment of low-barrier data analysis platforms that allow for adaptive instruction and the study of data science as a science."
  },
  {
    "objectID": "people/executive/yurko-ron.html",
    "href": "people/executive/yurko-ron.html",
    "title": "Ron Yurko",
    "section": "",
    "text": "Home\n    People\n    Executive team\n    Ron Yurko"
  },
  {
    "objectID": "people/executive/yurko-ron.html#biography",
    "href": "people/executive/yurko-ron.html#biography",
    "title": "Ron Yurko",
    "section": "Biography",
    "text": "Biography\nRon Yurko is an Assistant Teaching Professor in the Department of Statistics & Data Science at Carnegie Mellon University. He received his PhD in Statistics at CMU in 2022 under supervision of Professor Kathryn Roeder and Professor Max G’Sell. His research focuses on developing methods at the interface of inference and machine learning, oriented towards problems in statistical genetics and sports analytics. Previously, he received his BS in Statistics (also) at CMU in 2015, briefly worked in finance, as well as with the Pittsburgh Pirates and Zelus Analytics."
  },
  {
    "objectID": "people/staff/ellingwood-meg.html",
    "href": "people/staff/ellingwood-meg.html",
    "title": "Meg Ellingwood",
    "section": "",
    "text": "Home\n    People\n    Instructors\n    Meg Ellingwood"
  },
  {
    "objectID": "people/staff/ellingwood-meg.html#biography",
    "href": "people/staff/ellingwood-meg.html#biography",
    "title": "Meg Ellingwood",
    "section": "Biography",
    "text": "Biography\nMeg Ellingwood is a second-year student in the PhD program in statistics at CMU. She graduated from Kenyon College and briefly taught high school statistics before entering graduate school. Meg participated as a student in CMSACamp Summer 2020, as a TA in Summer 2021 and 2022, and she is thrilled to be an instructor this summer. She is interested in applications of statistics and data science in sports, public health, and neuroscience."
  },
  {
    "objectID": "people/staff/shrotriya-shamindra.html",
    "href": "people/staff/shrotriya-shamindra.html",
    "title": "Shamindra Shrotriya",
    "section": "",
    "text": "Home\n    People\n    Instructors\n    Shamindra Shrotriya"
  },
  {
    "objectID": "people/staff/shrotriya-shamindra.html#biography",
    "href": "people/staff/shrotriya-shamindra.html#biography",
    "title": "Shamindra Shrotriya",
    "section": "Biography",
    "text": "Biography\nShamindra received his PhD from the Department of Statistics & Data Science at Carnegie Mellon University in Fall 2022. He was extremely fortunate to be advised by Matey Neykov. Shamindra’s primary research interests focus on density estimation, isotonic regression, and location-scale estimation. He is also actively interested in application-driven methodology, including spatiotemporal modeling (wildfire prediction), and also statistical ranking. In the latter case, he was fortunate to present a paper at the CMSACamp in 2019.\nPrior to his PhD, he worked for eight years in industry first as a private and public sector actuary, before then branching out into broader data science and data engineering in the online and supermarket retail sectors. He also holds a MA in Statistics from UC Berkeley, and a BCom majoring in Actuarial Studies and Finance from the University of New South Wales, Australia.\nHe grew up in Australia, so feel free to talk to him about cricket, rugby union, etc. But importantly reach out to him with any queries during SURE 2023!"
  },
  {
    "objectID": "people/student_support/chapman-leeann.html",
    "href": "people/student_support/chapman-leeann.html",
    "title": "LeeAnn Chapman",
    "section": "",
    "text": "Home\n    People\n    Student Support\n    LeeAnn Chapman"
  },
  {
    "objectID": "people/student_support/chapman-leeann.html#biography",
    "href": "people/student_support/chapman-leeann.html#biography",
    "title": "LeeAnn Chapman",
    "section": "Biography",
    "text": "Biography\nLee Ann Chapman is an Accounting Assistant in the Department of Statistics and Data Science. Moving back to Pittsburgh from Florida, Lee Ann joined the department in 2022 and works closely with the department Business Manager with the daily financial function of the department as well as assisting the Program Administrator with various departmental events throughout the year."
  },
  {
    "objectID": "people/student_support/clune-glenn.html",
    "href": "people/student_support/clune-glenn.html",
    "title": "Glenn Clune",
    "section": "",
    "text": "Home\n    People\n    Student Support\n    Glenn Clune"
  },
  {
    "objectID": "people/student_support/clune-glenn.html#biography",
    "href": "people/student_support/clune-glenn.html#biography",
    "title": "Glenn Clune",
    "section": "Biography",
    "text": "Biography\nGlenn Clune is part of the undergraduate advising team for our Statistics & Data Science students. Starting with the department in the summer of 2018, he has continually strived to help students feel welcome and supported during their time with the department, and has maintained a particular commitment to supporting first generation, underrepresented and underprivileged students navigate through the challenges of higher education."
  },
  {
    "objectID": "people/student_support/paschke-jessica.html",
    "href": "people/student_support/paschke-jessica.html",
    "title": "Jessica Paschke",
    "section": "",
    "text": "Home\n    People\n    Student Support\n    Jessica Paschke"
  },
  {
    "objectID": "people/student_support/paschke-jessica.html#biography",
    "href": "people/student_support/paschke-jessica.html#biography",
    "title": "Jessica Paschke",
    "section": "Biography",
    "text": "Biography\nJess Paschke is the Assistant Business Manager and Project Administrator for the Department of Statistics & Data Science. She began working with the department in 2014. Jess works closely with the Department Head and Business Manager on large department events, projects, and programs."
  },
  {
    "objectID": "people/student_support/white-teraya.html",
    "href": "people/student_support/white-teraya.html",
    "title": "Teraya White",
    "section": "",
    "text": "Home\n    People\n    Student Support\n    Teraya White"
  },
  {
    "objectID": "people/student_support/white-teraya.html#biography",
    "href": "people/student_support/white-teraya.html#biography",
    "title": "Teraya White",
    "section": "Biography",
    "text": "Biography\nAs the Academic Program Manager for Carnegie Mellon University’s Master of Statistical Practice (MSP) Program in the Department of Statistics & Data Science, Teraya works closely with students on developing industry-valued competencies and navigating a highly dynamic job market. She is a champion for Diversity, Equity, and Inclusion within the Dietrich College of Humanities and Social Sciences, expanding CMU’s recruiting presence at Historically Black Colleges and Universities (HBCUs) and presenting educational opportunities to historically underrepresented groups at the American Statistical Society-sponsored StatFest conference.\nTeraya also assists with the popular Pittsburgh Women in Data Science conference (WiDS), featuring thought leadership shared by women speakers from academia and industry. She also co-led the recruiting of Pittsburgh Public Schools students for a data science summer program in the Department of Statistics & Data Sciences at Carnegie Mellon University."
  },
  {
    "objectID": "people/ta/chen-yuchen.html",
    "href": "people/ta/chen-yuchen.html",
    "title": "Yuchen Chen",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Yuchen Chen"
  },
  {
    "objectID": "people/ta/chen-yuchen.html#biography",
    "href": "people/ta/chen-yuchen.html#biography",
    "title": "Yuchen Chen",
    "section": "Biography",
    "text": "Biography\nYuchen Chen is a first year PhD student in statistics at CMU. His research interests are in survival analysis, semi-parametric statistics and distribution-free inference. He received a BA in Mathematics at the University of Chicago."
  },
  {
    "objectID": "people/ta/choe-yj.html",
    "href": "people/ta/choe-yj.html",
    "title": "YJ Choe",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    YJ Choe\n  \n\n\n  \n \n \n  \n   \n  \n    \n     github\n  \n  \n    \n     website\n  \n\n\n\nYJ Choe is a fifth-year joint Ph.D. student in Statistics and Machine Learning at Carnegie Mellon University, advised by Prof. Aaditya Ramdas. He is broadly interested in statistical machine learning, with a recent focus on sequential inference, game-theoretic statistics, forecast evaluation, and causal inference. Previously, YJ was an industry researcher working on deep learning methods for natural language processing."
  },
  {
    "objectID": "people/ta/kissel-nick.html",
    "href": "people/ta/kissel-nick.html",
    "title": "Nick Kissel",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Nick Kissel"
  },
  {
    "objectID": "people/ta/kissel-nick.html#biography",
    "href": "people/ta/kissel-nick.html#biography",
    "title": "Nick Kissel",
    "section": "Biography",
    "text": "Biography\nNicholas Kissel is a fourth year statistics PhD student at CMU. He received an MS in statistics and BS in math & statistics from Pitt in 2019. He is primarily interested in developing methods for generating model confidence sets. More broadly, he is interested in creating inferential procedures for machine learning modeling methods, as well as developing accessible statistical tools that are applicable to natural and social science research."
  },
  {
    "objectID": "people/ta/mcclean-alec.html",
    "href": "people/ta/mcclean-alec.html",
    "title": "Alec McClean",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Alec McClean"
  },
  {
    "objectID": "people/ta/mcclean-alec.html#biography",
    "href": "people/ta/mcclean-alec.html#biography",
    "title": "Alec McClean",
    "section": "Biography",
    "text": "Biography\nAlec McClean is a fourth year PhD student at CMU. His research interests are at the intersection of statistics, machine learning, and causal inference. He received a BA in Mathematics and Economics from Swarthmore College in 2016."
  },
  {
    "objectID": "people/ta/nguyen-quang.html",
    "href": "people/ta/nguyen-quang.html",
    "title": "Quang Nguyen",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Quang Nguyen"
  },
  {
    "objectID": "people/ta/nguyen-quang.html#biography",
    "href": "people/ta/nguyen-quang.html#biography",
    "title": "Quang Nguyen",
    "section": "Biography",
    "text": "Biography\nQuang Nguyen is a first year PhD student in the Department of Statistics and Data Science at CMU. His current research is on statistical network analysis with application in criminology. He is also broadly interested in applications of statistics and machine learning in sports with focus on player tracking data. Quang previously received his MS in Applied Statistics from Loyola University Chicago and BS in Mathematics and Data Science from Wittenberg University. He is a die-hard supporter of Manchester United."
  },
  {
    "objectID": "people/ta/park-beomjo.html",
    "href": "people/ta/park-beomjo.html",
    "title": "Beomjo Park",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Beomjo Park"
  },
  {
    "objectID": "people/ta/park-beomjo.html#biography",
    "href": "people/ta/park-beomjo.html#biography",
    "title": "Beomjo Park",
    "section": "Biography",
    "text": "Biography\nBeomjo Park is a fifth-year Ph.D. student in the Dept. of Statistics & Data Science at Carnegie Mellon University. Under the guidance of Sivaraman Balakrishnan and Larry Wasserman, his research focuses on robust statistical inference, specifically addressing model misspecification and data corruption. His previous work includes interdisciplinary applications in Oceanography and Biostatistics, with a central emphasis on Bayesian semiparametric models and variational inference."
  },
  {
    "objectID": "people/ta/prasadan-akshay.html",
    "href": "people/ta/prasadan-akshay.html",
    "title": "Akshay Prasadan",
    "section": "",
    "text": "Home\n    People\n    TA Advisors\n    Akshay Prasadan"
  },
  {
    "objectID": "people/ta/prasadan-akshay.html#biography",
    "href": "people/ta/prasadan-akshay.html#biography",
    "title": "Akshay Prasadan",
    "section": "Biography",
    "text": "Biography\nAkshay Prasadan is a third year PhD student at CMU, working with Matey Neykov on research topics in the areas of minimax theory, constrained estimation, and Gaussian sequence models. He received a BS in Mathematics and Economics at The Ohio State University. He is a Pittsburgh local and is passionate about the stock market."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester!\n\nLecture (): This page contains the slides (and additional readings) for the data science or data engineering lectures. These materials will typically be released right after each class, and in some cases, directly before the class.\nAssignment (): This page contains the instructions for each assignment, i.e., demo-lab or final research project materials.\n\n\nOrientation\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nIntroduction\n\n\n\n\nJune 5\n\n\nWelcome to SURE 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nData Exploring\n\n\n\n\nJune 5\n\n\nDemo-lab: Rstudio basics\n\n\n\n\n\n\n\n\n\n\nJune 6\n\n\nExploring data: Into the tidyverse\n\n\n\n\n\n\n\n\n\n\nJune 7\n\n\nThe grammar of graphics and ggplot2\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\n\nJune 7\n\n\nDemo-lab: wrangling with dplyr\n\n\n\n\n\n\n\n\n\n\nJune 8\n\n\nVisualizing 1D categorical and continuous variables\n\n\n\n\n\n\n\n\n\n\nJune 8\n\n\nEDA Mini-Project 1: Requirements and DataCMSAC mini project: in lieu of their research project starting in two weeks later.\n\n\n\n\n\n\n\n\n\n\nJune 9\n\n\nVisualizing 2D categorical and continuous by categorical\n\n\n\n\n\n\n\n\n\n\nJune 12\n\n\nDensity estimation\n\n\n\n\n\n\n\n\n\n\nJune 12\n\n\nDemo-lab: Data visualization practice with ggplot\n\n\n\n\n\n\n\n\n\n\nJune 16\n\n\nGeographical EDA using Shapefiles\n\n\n\n\n\n\n\n\n\n\nJune 16\n\n\nDemo-lab: Exploratory data analysis case studies\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Engineering\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nUNIX Philosophy\n\n\n\n\nJune 6\n\n\nGetting acquainted with the UNIX philosophy\n\n\n\n\n\n\n\n\n\n\nJune 13\n\n\nGetting comfortable with the UNIX philosophy\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupervised Learning\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nClustering\n\n\n\n\nJune 13\n\n\nK-means\n\n\n\n\n\n\n\n\n\n\nJune 14\n\n\nHierarchical clustering\n\n\n\n\n\n\n\n\n\n\nJune 15\n\n\nGaussian mixture models\n\n\n\n\n\n\n\n\n\n\nJune 19\n\n\nDemo-lab: clusteringJuneteenth holiday, but lab will be released\n\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation Skills\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nPresenting\n\n\n\n\nJune 20\n\n\nWorking with xaringan and xaringanthemer\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nSupervised Learning\n\n\n\n\nJune 21\n\n\nModel assessment vs selection\n\n\n\n\n\n\n\n\n\n\nJune 22\n\n\nLinear regression\n\n\n\n\n\n\n\n\n\n\nJune 23\n\n\nIntro to variable selection\n\n\n\n\n\n\n\n\n\n\nJune 26\n\n\nRegularization\n\n\n\n\n\n\n\n\n\n\nJune 26\n\n\nDemo-lab: Linear regression\n\n\n\n\n\n\n\n\n\n\nJune 27\n\n\nSupervised and unsupervised learning with Tidymodels\n\n\n\n\n\n\n\n\n\n\nJune 28\n\n\nDimension Reduction: Principal components analysis (PCA)\n\n\n\n\n\n\n\n\n\n\nJune 29\n\n\nPrincipal component regression and partial least squares\n\n\n\n\n\n\n\n\n\n\nJune 30\n\n\nGeneralized linear models (GLMs)\n\n\n\n\n\n\n\n\n\n\nJuly 6\n\n\nLogistic regression\n\n\n\n\n\n\n\n\n\n\nJuly 7\n\n\nNonparametric regression\n\n\n\n\n\n\n\n\n\n\nJuly 10\n\n\nDemo lab: PCA and more regression\n\n\n\n\n\n\n\n\n\n\nSupervised and Unsupervised Learning\n\n\n\n\nJuly 10\n\n\nDecision trees\n\n\n\n\n\n\n\n\n\n\nJuly 11\n\n\nRandom forests and gradient-boosted trees\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal project\n\n\n\n\n\n\n\nTitle\n\n\nLecture\n\n\nAssignment\n\n\n\n\n\n\nFinal project\n\n\n\n\nJuly 27\n\n\nOptum Research Project Specification\n\n\n\n\n\n\n\n\n\n\nJuly 27\n\n\nCMSAC Research Project Specification\n\n\n\n\n\n\n\n\n\n\nJuly 27\n\n\nSURE 2023: Report Writing Guideline"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to the Summer Undergraduate Research Experience (SURE) 2023. The purpose of this program is to explore cutting-edge statistics and data science methodology with applications in healthcare and sports analytics.\nSURE 2023 is only made possible through the generous and ongoing support by our program partners in healthcare (Optum), and sports data science (CMSAC)."
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nLectures will be delivered to both Optum and CMSAC students together. Each morning, we will cover topics in data science, including: data wrangling, exploratory data analysis, and both supervised/unsupervised learning. Separately, Tuesday afternoons will feature lectures on data engineering, including: the UNIX, SQL, tmux, etc.."
  },
  {
    "objectID": "syllabus.html#domain-specific-presentations",
    "href": "syllabus.html#domain-specific-presentations",
    "title": "Syllabus",
    "section": "Domain-specific presentations",
    "text": "Domain-specific presentations\nAround mid-day, most days of the summer, you will also have presentations from industry professionals in your domain area. On the Optum side, there is a full slate of mandatory virtual talks from members of the United Health Group (UHG) to familiarize you with the work they do and give career advice. These are a fantastic networking opportunity for Optum students for future career opportunities. For the sports side, the first few weeks will involve sports analysts coming in to pitch projects in baseball, hockey, basketball, and soccer. You’ll have the chance to then choose one of these projects to work on for the rest of the summer. There will also be various visitors later on to speak about working in sports analytics."
  },
  {
    "objectID": "syllabus.html#demo-labs",
    "href": "syllabus.html#demo-labs",
    "title": "Syllabus",
    "section": "Demo labs",
    "text": "Demo labs\nThen, on Monday afternoons (and some Wednesdays at the beginning of the program), you’ll be able to get hands-on practice applying methods in data science with demo labs run by the program TAs. These labs will be conducted separately for the two groups. All materials (Optum and CMSAC) will be made available on this course website, if you want extra practice from both health and sports domains."
  },
  {
    "objectID": "syllabus.html#project-labs",
    "href": "syllabus.html#project-labs",
    "title": "Syllabus",
    "section": "Project labs",
    "text": "Project labs\nFinally, the most important component of the program is the research project, and associated deliverables. In dedicated project-lab sessions, you’ll work in a group of 2-4 students to analyze a dataset in health or sports analytics to answer a research question that is important to practitioners in your field. Past projects have examined geographic differences in the impact of the opioid epidemic, built models to predict passing or running plays in the NFL, and performed cluster analysis of NBA and WNBA players. At the end of the program, you’ll hand in a report summarizing your findings, create a poster, and deliver a short presentation to the community and project stakeholders."
  },
  {
    "objectID": "syllabus.html#course-website",
    "href": "syllabus.html#course-website",
    "title": "Syllabus",
    "section": "Course Website",
    "text": "Course Website\nThis SURE 2023 website will be the main “home base” for the entirety of the program. You are expected to check it regularly throughout each day in the program for any updates. All lecture and demo-lab materials will be provided on the site, freely available. As stated before, there is no textbook for this program, just lecture slides that you’ll be able to access via the schedule. There you will also find specifications for the projects and lab files.\nFor non-academic concerns, we have compiled a list of helpful guides, e.g., computing setup, Pittsburgh-based resources, fun local activities. We also have dedicated staff bios to help you quickly find the right person for any questions that might arise. Keep browsing around, we’ll keep adding to it over the program to make it your ‘one-stop-shop’ for all your major concerns."
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nIn addition to the website, we will be using an online calendar, which you can and should add to your personal scheduling software of choice (Google, iCal, Outlook, etc.), and which you will be expected to keep track of. You will receive a link to this calendar via email. It will be the most up-to-date source of information about when and where things will be happening in the program.\nA glimpse of a ‘typical’ week, via the Google Calendar, is as follows:\n\n\n\nAs mentioned, data-science lectures for all SURE 2023 students will take place in the morning. Then there will be separate presentations for the Optum and CMSAC groups around lunchtime, and in the afternoon we will have demo-labs, data-engineering, and project labs. As mentioned, you are expected to attend program activities in-person during the standard workday.\nAll SURE and Optum-only activities will take place in Posner Hall (POS 151). All CMSAC will take place in Porter Hall (PH A18A) for the duration of the program. Just two rooms to remember, how easy is that!\nIn terms of lecture and lab contents, please regularly refer to the schedule. Please note that the planned schedule is subject to change at the discretion of the teaching staff.\n\nBreaks and Holidays\nIt’s important to take good rest during research. Aside from weekend breaks, we have the following planned breaks and holidays during the program\n\nJuneteenth: Monday 06/19.\nIndependence Day break: Monday 07/03 to Wed 07/05 (inclusive)\n(Optum only) site visit: Monday 07/17 to Thu 07/20 (inclusive)"
  },
  {
    "objectID": "syllabus.html#using-slack-effectively",
    "href": "syllabus.html#using-slack-effectively",
    "title": "Syllabus",
    "section": "Using Slack effectively",
    "text": "Using Slack effectively\nYou will receive an invitation to a Slack workspace for the summer program. This will be the main communication channel for students, faculty, and staff for real time announcements and quick questions. You should check Slack frequently, especially during working hours. Slack messages are preferable to emails, but if official channels are required then email may be more appropriate.\nIn order to use Slack effectively, please note the following guidelines. Akshay and Yuchen will be the Slack Champions who will help manage our Slack workspace according to these guidelines.\n\nAsk each other/teaching staff questions first.\n\nWe encourage you to reach out to your peers in DMs, group chats, in-person, etc. for help before pinging a TA or instructor.\nComplicated statistical/programming questions are best asked in person during office hours or labs.\n\nSlack etiquette\n\nTo keep the channels organized, please respond using threads, as opposed to starting a new thread each message.\nMemes and off-topic discussions should be posted outside of the main channels, in their own dedicated #random channel.\nAll Slack communication must abide by the code of conduct.\n\nPublic channels\n\n#announcements: All major program-wide announcements will be posted here, e.g., room changes and lunch logistics.\n#general: Questions/discussion pertaining to the broader program (Optum or CMSAC)\n#random: Post your memes, off-topic conversations, outside-events, etc.\n\nPrivate channels\n\n#optum: Private channel for Optum students only and course instructors\n#cmsac: Private channel for CMSAC students only and course instructors\nProject Groups: During the first week, each research group and their TA advisor should create a private channel for their day-to-day communication.\n\nFixed usage hours\n\nTAs or Instructors will generally be active and responsive on Slack during program hours, i.e., 9:30am-4pm weekdays, not on weekends/holidays, etc."
  }
]